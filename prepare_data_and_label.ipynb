{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dramatic-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import medleydb as mdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-simon",
   "metadata": {},
   "source": [
    "# ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "furnished-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from joblib import Parallel, delayed\n",
    "import librosa\n",
    "import medleydb as mdb\n",
    "from medleydb import mix\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.signal import upfirdn\n",
    "from scipy.ndimage import filters\n",
    "import sox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hungarian-python",
   "metadata": {
    "code_folding": [
     114,
     149,
     165
    ]
   },
   "outputs": [],
   "source": [
    "def get_hcqt_params():\n",
    "    \"\"\"Hack to always use the same parameters :)\n",
    "    \"\"\"\n",
    "    bins_per_octave = 60\n",
    "    n_octaves = 6\n",
    "    harmonics = [0.5, 1, 2, 3, 4, 5]\n",
    "    sr = 22050\n",
    "    fmin = 32.7\n",
    "    hop_length = 256\n",
    "    return bins_per_octave, n_octaves, harmonics, sr, fmin, hop_length\n",
    "\n",
    "def compute_hcqt(audio_fpath):\n",
    "    \"\"\"Compute the harmonic CQT from a given audio file\n",
    "    \"\"\"\n",
    "    (bins_per_octave, n_octaves, harmonics,\n",
    "     sr, f_min, hop_length) = get_hcqt_params()\n",
    "    y, fs = librosa.load(audio_fpath, sr=sr)\n",
    "\n",
    "    cqt_list = []\n",
    "    shapes = []\n",
    "    for h in harmonics:\n",
    "        cqt = librosa.cqt(\n",
    "            y, sr=fs, hop_length=hop_length, fmin=f_min*float(h),\n",
    "            n_bins=bins_per_octave*n_octaves,\n",
    "            bins_per_octave=bins_per_octave\n",
    "        )\n",
    "        cqt_list.append(cqt)\n",
    "        shapes.append(cqt.shape)\n",
    "\n",
    "    shapes_equal = [s == shapes[0] for s in shapes]\n",
    "    if not all(shapes_equal):\n",
    "        min_time = np.min([s[1] for s in shapes])\n",
    "        new_cqt_list = []\n",
    "        for i in range(len(cqt_list)):\n",
    "            new_cqt_list.append(cqt_list[i][:, :min_time])\n",
    "        cqt_list = new_cqt_list\n",
    "\n",
    "    log_hcqt = ((1.0/80.0) * librosa.core.amplitude_to_db(\n",
    "        np.abs(np.array(cqt_list)), ref=np.max)) + 1.0\n",
    "\n",
    "    return log_hcqt\n",
    "\n",
    "def get_freq_grid():\n",
    "    \"\"\"Get the hcqt frequency grid\n",
    "    \"\"\"\n",
    "    (bins_per_octave, n_octaves, _, _, f_min, _) = get_hcqt_params()\n",
    "    freq_grid = librosa.cqt_frequencies( #Compute the center frequencies of Constant-Q bins.\n",
    "        bins_per_octave*n_octaves, f_min, bins_per_octave=bins_per_octave\n",
    "    )\n",
    "    return freq_grid\n",
    "\n",
    "def get_time_grid(n_time_frames):\n",
    "    \"\"\"Get the hcqt time grid\n",
    "    \"\"\"\n",
    "    (_, _, _, sr, _, hop_length) = get_hcqt_params()\n",
    "    time_grid = librosa.core.frames_to_time(\n",
    "        range(n_time_frames), sr=sr, hop_length=hop_length\n",
    "    )\n",
    "    return time_grid\n",
    "\n",
    "def grid_to_bins(grid, start_bin_val, end_bin_val):\n",
    "    \"\"\"Compute the bin numbers from a given grid\n",
    "    \"\"\"\n",
    "    bin_centers = (grid[1:] + grid[:-1])/2.0\n",
    "    bins = np.concatenate([[start_bin_val], bin_centers, [end_bin_val]])\n",
    "    return bins\n",
    "\n",
    "\n",
    "def create_annotation_target(freq_grid, time_grid, annotation_times,\n",
    "                             annotation_freqs, gaussian_blur):\n",
    "    \"\"\"Create the binary annotation target labels\n",
    "    \"\"\"\n",
    "    time_bins = grid_to_bins(time_grid, 0.0, time_grid[-1]) # dim += 1 分界线\n",
    "    freq_bins = grid_to_bins(freq_grid, 0.0, freq_grid[-1]) # dim += 1 分界线\n",
    "    # time_grid freq_grid的值表示每个像素代表范围的中间值\n",
    "    # time_grid牵强，因为它的首元素是0……以后再说\n",
    "\n",
    "    annot_time_idx = np.digitize(annotation_times, time_bins) - 1\n",
    "    annot_freq_idx = np.digitize(annotation_freqs, freq_bins) - 1\n",
    "\n",
    "    n_freqs = len(freq_grid)\n",
    "    n_times = len(time_grid)\n",
    "\n",
    "    idx = annot_time_idx < n_times\n",
    "    annot_time_idx = annot_time_idx[idx]\n",
    "    annot_freq_idx = annot_freq_idx[idx]\n",
    "\n",
    "    idx2 = annot_freq_idx < n_freqs\n",
    "    annot_time_idx = annot_time_idx[idx2]\n",
    "    annot_freq_idx = annot_freq_idx[idx2]\n",
    "\n",
    "    annotation_target = np.zeros((n_freqs, n_times))\n",
    "    annotation_target[annot_freq_idx, annot_time_idx] = 1\n",
    "\n",
    "    if not gaussian_blur:\n",
    "        return annotation_target\n",
    "        '''can skip now'''\n",
    "    else:\n",
    "        annotation_target_blur = filters.gaussian_filter1d(\n",
    "            annotation_target, 1, axis=0, mode='constant'\n",
    "        )\n",
    "        if len(annot_freq_idx) > 0:\n",
    "            min_target = np.min(\n",
    "                annotation_target_blur[annot_freq_idx, annot_time_idx]\n",
    "            )\n",
    "        else:\n",
    "            min_target = 1.0\n",
    "\n",
    "        annotation_target_blur = annotation_target_blur / min_target\n",
    "        annotation_target_blur[annotation_target_blur > 1.0] = 1.0\n",
    "\n",
    "        return annotation_target_blur\n",
    "    \n",
    "\n",
    "def get_input_output_pairs(audio_fpath, annot_times, annot_freqs,\n",
    "                           gaussian_blur, precomputed_hcqt=None):\n",
    "    # audio_fpath: mix path\n",
    "    if precomputed_hcqt is None or not os.path.exists(precomputed_hcqt):\n",
    "        print(\"    > computing CQT for {}\".format(os.path.basename(audio_fpath)))\n",
    "        hcqt = compute_hcqt(audio_fpath)\n",
    "    else:\n",
    "        print(\"    > using precomputed CQT for {}\".format(os.path.basename(audio_fpath)))\n",
    "        hcqt = np.load(precomputed_hcqt, mmap_mode='r')\n",
    "\n",
    "    freq_grid = get_freq_grid()\n",
    "    time_grid = get_time_grid(len(hcqt[0][0]))\n",
    "\n",
    "    annot_target = create_annotation_target(\n",
    "        freq_grid, time_grid, annot_times, annot_freqs, gaussian_blur\n",
    "    )\n",
    "\n",
    "    return hcqt, annot_target, freq_grid, time_grid\n",
    "\n",
    "\n",
    "def save_data(save_path, prefix, X, Y, f, t):\n",
    "    input_path = os.path.join(save_path, 'inputs')\n",
    "    output_path = os.path.join(save_path, 'outputs')\n",
    "    if not os.path.exists(input_path):\n",
    "        os.mkdir(input_path)\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "\n",
    "    np.save(os.path.join(input_path, \"{}_input.hcqt.npy\".format(prefix)), X.astype(np.float32))\n",
    "    np.save(os.path.join(output_path, \"{}_output.npy\".format(prefix)), Y.astype(np.float32))\n",
    "\n",
    "    print(\"    Saved data for {} to {}\".format(prefix, save_path))\n",
    "\n",
    "\n",
    "\n",
    "def compute_melody2(mtrack, save_dir, gaussian_blur, precomputed_hcqt):\n",
    "    data = mtrack.melody2_annotation\n",
    "    if data is None:\n",
    "        print(\"    {} No melody 2 data\".format(mtrack.track_id))\n",
    "    else:\n",
    "        prefix = \"{}_mel2\".format(mtrack.track_id)\n",
    "\n",
    "        input_path = os.path.join(save_dir, 'inputs', \"{}_input.npy\".format(prefix))\n",
    "        output_path = os.path.join(save_dir, 'outputs', \"{}_output.npy\".format(prefix))\n",
    "        if os.path.exists(input_path) and os.path.exists(output_path):\n",
    "            print(\"    > already done!\")\n",
    "            return\n",
    "\n",
    "        annot = np.array(data).T\n",
    "        times = annot[0]\n",
    "        freqs = annot[1]\n",
    "\n",
    "        idx = np.where(freqs != 0.0)[0] # 返回满足条件的索引\n",
    "\n",
    "        times = times[idx]\n",
    "        freqs = freqs[idx]\n",
    "\n",
    "        X, Y, f, t = get_input_output_pairs(\n",
    "            mtrack.mix_path, times, freqs, gaussian_blur,\n",
    "            precomputed_hcqt\n",
    "        )\n",
    "        save_data(save_dir, prefix, X, Y, f, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-abraham",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    list_108 = []\n",
    "    for track in mdb.load_all_multitracks():\n",
    "        if track.has_melody:\n",
    "            list_108.append(track.track_id)\n",
    "    assert(len(list_108)==108)\n",
    "\n",
    "    for track_id in tqdm(list_108):\n",
    "        a = mdb.MultiTrack(track_id)\n",
    "        compute_melody2(a, '.', gaussian_blur=False,precomputed_hcqt=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "received-receipt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.\n",
      "[NbConvertApp] Converting notebook prepare_data_and_label.ipynb to python\n",
      "[NbConvertApp] Writing 6878 bytes to prepare_data_and_label.py\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    !jupyter nbconvert --to python prepare_data_and_label.ipynb\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-johnston",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
