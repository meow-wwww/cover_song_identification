Using cuda device
--------------ArgParse--------------
Save_dir model/check_same already exist. Will save to this directory.
Don't use saved model, train from scratch
Using lr from command: lr=1e-06
2021-07-11 22:03:19.635480 - Preparing train_dataloader...
2021-07-11 22:03:28.405539 - Preparing valid_dataloader...
raw model
Adjusting learning rate of group 0 to 1.0000e-06.
Epoch 1
-------------------------------2021-07-11 22:03:30.787307
Avg loss: 2.8986  [ 1600/24705]
Avg loss: 2.1837  [ 3200/24705]
Avg loss: 2.2525  [ 4800/24705]
Avg loss: 1.8070  [ 6400/24705]
Avg loss: 1.6668  [ 8000/24705]
Avg loss: 2.0379  [ 9600/24705]
Avg loss: 1.6204  [11200/24705]
Avg loss: 1.6882  [12800/24705]
Avg loss: 1.4703  [14400/24705]
Avg loss: 1.5286  [16000/24705]
Avg loss: 1.8123  [17600/24705]
Avg loss: 1.7254  [19200/24705]
Avg loss: 1.1476  [20800/24705]
Avg loss: 1.8271  [22400/24705]
Avg loss: 1.3585  [24000/24705]
Adjusting learning rate of group 0 to 9.4000e-07.
Test Error: Avg loss: 1.8335 

Test OA	0.3703	VR	0.9995	VFA	0.9915	RPA	0.5104	RCA	0.5287

[in epoch 1, OA got new best: from 0 to 0.37027377601148087. Will save the model]
Epoch 2
-------------------------------2021-07-11 22:12:01.944655
Avg loss: 1.6546  [ 1600/24705]
Avg loss: 1.7498  [ 3200/24705]
Avg loss: 1.6480  [ 4800/24705]
Avg loss: 1.5132  [ 6400/24705]
Avg loss: 1.4891  [ 8000/24705]
Avg loss: 1.1856  [ 9600/24705]
Avg loss: 1.2885  [11200/24705]
Avg loss: 1.2591  [12800/24705]
Avg loss: 1.3457  [14400/24705]
Avg loss: 1.5097  [16000/24705]
Avg loss: 1.7812  [17600/24705]
Avg loss: 1.4399  [19200/24705]
Avg loss: 1.1294  [20800/24705]
Avg loss: 1.1160  [22400/24705]
Avg loss: 0.7736  [24000/24705]
Adjusting learning rate of group 0 to 8.8360e-07.
Test Error: Avg loss: 1.7087 

Test OA	0.3892	VR	1.0000	VFA	0.9944	RPA	0.5383	RCA	0.5551

[in epoch 2, OA got new best: from 0.37027377601148087 to 0.3892028205552795. Will save the model]
Epoch 3
-------------------------------2021-07-11 22:21:00.185725
Avg loss: 1.0737  [ 1600/24705]
Avg loss: 0.8973  [ 3200/24705]
Avg loss: 1.2184  [ 4800/24705]
Avg loss: 1.1015  [ 6400/24705]
Avg loss: 1.5412  [ 8000/24705]
Avg loss: 1.2040  [ 9600/24705]
Avg loss: 1.4107  [11200/24705]
Avg loss: 1.0964  [12800/24705]
Avg loss: 1.1729  [14400/24705]
Avg loss: 1.1754  [16000/24705]
Avg loss: 1.5321  [17600/24705]
Avg loss: 1.3108  [19200/24705]
Avg loss: 1.1811  [20800/24705]
Avg loss: 1.0628  [22400/24705]
Avg loss: 1.2679  [24000/24705]
Adjusting learning rate of group 0 to 8.3058e-07.
Test Error: Avg loss: 1.6229 

Test OA	0.3992	VR	1.0000	VFA	0.9948	RPA	0.5528	RCA	0.5665

[in epoch 3, OA got new best: from 0.3892028205552795 to 0.3992072362974001. Will save the model]
Epoch 4
-------------------------------2021-07-11 22:29:32.030931
Avg loss: 1.1705  [ 1600/24705]
Avg loss: 1.3588  [ 3200/24705]
Avg loss: 1.1444  [ 4800/24705]
Avg loss: 1.0647  [ 6400/24705]
Avg loss: 1.2828  [ 8000/24705]
Avg loss: 1.0182  [ 9600/24705]
Avg loss: 0.9330  [11200/24705]
Avg loss: 1.1493  [12800/24705]
Avg loss: 1.3273  [14400/24705]
Avg loss: 1.2874  [16000/24705]
Avg loss: 1.4239  [17600/24705]
Avg loss: 1.2557  [19200/24705]
Avg loss: 1.5436  [20800/24705]
Avg loss: 1.1431  [22400/24705]
Avg loss: 1.1212  [24000/24705]
Adjusting learning rate of group 0 to 7.8075e-07.
Test Error: Avg loss: 1.6367 

Test OA	0.4027	VR	1.0000	VFA	0.9951	RPA	0.5562	RCA	0.5697

[in epoch 4, OA got new best: from 0.3992072362974001 to 0.4027087818071423. Will save the model]
Epoch 5
-------------------------------2021-07-11 22:38:04.892251
Avg loss: 0.9900  [ 1600/24705]
Avg loss: 1.1083  [ 3200/24705]
Avg loss: 1.0557  [ 4800/24705]
Avg loss: 1.3904  [ 6400/24705]
Avg loss: 1.2341  [ 8000/24705]
Avg loss: 0.9515  [ 9600/24705]
Avg loss: 1.0257  [11200/24705]
Avg loss: 1.3555  [12800/24705]
Avg loss: 1.1501  [14400/24705]
Avg loss: 1.1151  [16000/24705]
Avg loss: 1.2438  [17600/24705]
Avg loss: 1.0152  [19200/24705]
Avg loss: 1.3944  [20800/24705]
Avg loss: 0.8913  [22400/24705]
Avg loss: 0.8792  [24000/24705]
Adjusting learning rate of group 0 to 7.3390e-07.
Test Error: Avg loss: 1.5897 

Test OA	0.4051	VR	1.0000	VFA	0.9958	RPA	0.5610	RCA	0.5737

[in epoch 5, OA got new best: from 0.4027087818071423 to 0.4050580946072748. Will save the model]
Epoch 6
-------------------------------2021-07-11 22:46:36.687770
Avg loss: 0.8976  [ 1600/24705]
Avg loss: 1.1941  [ 3200/24705]
Avg loss: 1.3376  [ 4800/24705]
Avg loss: 1.6192  [ 6400/24705]
Avg loss: 1.1983  [ 8000/24705]
Avg loss: 0.9954  [ 9600/24705]
Avg loss: 0.7322  [11200/24705]
Avg loss: 1.2472  [12800/24705]
Avg loss: 1.3361  [14400/24705]
Avg loss: 1.0140  [16000/24705]
Avg loss: 0.7851  [17600/24705]
Avg loss: 1.2125  [19200/24705]
Avg loss: 0.6493  [20800/24705]
Avg loss: 0.9124  [22400/24705]
Avg loss: 1.2217  [24000/24705]
Adjusting learning rate of group 0 to 6.8987e-07.
Test Error: Avg loss: 1.6077 

Test OA	0.4080	VR	1.0000	VFA	0.9960	RPA	0.5645	RCA	0.5774

[in epoch 6, OA got new best: from 0.4050580946072748 to 0.40801802174752994. Will save the model]
Epoch 7
-------------------------------2021-07-11 22:55:08.303782
Avg loss: 1.0720  [ 1600/24705]
Avg loss: 1.0960  [ 3200/24705]
Avg loss: 0.7968  [ 4800/24705]
Avg loss: 1.4599  [ 6400/24705]
Avg loss: 0.9048  [ 8000/24705]
Avg loss: 1.3176  [ 9600/24705]
Avg loss: 1.0183  [11200/24705]
Avg loss: 1.3768  [12800/24705]
Avg loss: 1.1126  [14400/24705]
Avg loss: 1.2595  [16000/24705]
Avg loss: 0.7805  [17600/24705]
Avg loss: 0.7228  [19200/24705]
Avg loss: 1.0917  [20800/24705]
Avg loss: 0.6530  [22400/24705]
Avg loss: 0.9172  [24000/24705]
Adjusting learning rate of group 0 to 6.4848e-07.
Test Error: Avg loss: 1.5976 

Test OA	0.4101	VR	1.0000	VFA	0.9956	RPA	0.5676	RCA	0.5804

[in epoch 7, OA got new best: from 0.40801802174752994 to 0.4101223988519069. Will save the model]
Epoch 8
-------------------------------2021-07-11 23:03:44.587844
Avg loss: 0.9081  [ 1600/24705]
Avg loss: 0.8383  [ 3200/24705]
Avg loss: 0.8747  [ 4800/24705]
Avg loss: 0.9637  [ 6400/24705]
Avg loss: 1.1397  [ 8000/24705]
Avg loss: 0.9703  [ 9600/24705]
Avg loss: 1.1194  [11200/24705]
Avg loss: 0.8854  [12800/24705]
Avg loss: 1.0376  [14400/24705]
Avg loss: 1.0742  [16000/24705]
Avg loss: 1.1477  [17600/24705]
Avg loss: 0.9797  [19200/24705]
Avg loss: 0.9179  [20800/24705]
Avg loss: 0.8021  [22400/24705]
Avg loss: 1.0587  [24000/24705]
Adjusting learning rate of group 0 to 6.0957e-07.
Test Error: Avg loss: 1.5586 

Test OA	0.4141	VR	1.0000	VFA	0.9961	RPA	0.5730	RCA	0.5858

[in epoch 8, OA got new best: from 0.4101223988519069 to 0.41405861897665175. Will save the model]
Epoch 9
-------------------------------2021-07-11 23:12:21.475137
Avg loss: 0.9182  [ 1600/24705]
Avg loss: 1.0441  [ 3200/24705]
Avg loss: 0.7530  [ 4800/24705]
Avg loss: 1.2498  [ 6400/24705]
Avg loss: 0.8510  [ 8000/24705]
Avg loss: 0.8223  [ 9600/24705]
Avg loss: 0.8516  [11200/24705]
Avg loss: 1.0874  [12800/24705]
Avg loss: 0.8458  [14400/24705]
Avg loss: 0.9488  [16000/24705]
Avg loss: 1.0781  [17600/24705]
Avg loss: 1.2677  [19200/24705]
Avg loss: 0.9303  [20800/24705]
Avg loss: 1.0992  [22400/24705]
Avg loss: 1.0370  [24000/24705]
Adjusting learning rate of group 0 to 5.7299e-07.
Test Error: Avg loss: 1.5852 

Test OA	0.4151	VR	1.0000	VFA	0.9962	RPA	0.5747	RCA	0.5880

[in epoch 9, OA got new best: from 0.41405861897665175 to 0.41509010873764984. Will save the model]
Epoch 10
-------------------------------2021-07-11 23:21:03.364925
Avg loss: 1.0228  [ 1600/24705]
Avg loss: 0.7320  [ 3200/24705]
Avg loss: 1.2153  [ 4800/24705]
Avg loss: 1.2272  [ 6400/24705]
Avg loss: 0.9219  [ 8000/24705]
Avg loss: 0.8700  [ 9600/24705]
Avg loss: 0.6655  [11200/24705]
Avg loss: 0.7981  [12800/24705]
Avg loss: 0.7878  [14400/24705]
Avg loss: 0.9162  [16000/24705]
Avg loss: 1.2364  [17600/24705]
Avg loss: 0.8927  [19200/24705]
Avg loss: 1.4107  [20800/24705]
Avg loss: 0.8056  [22400/24705]
Avg loss: 0.8200  [24000/24705]
Adjusting learning rate of group 0 to 5.3862e-07.
Test Error: Avg loss: 1.5795 

Test OA	0.4141	VR	1.0000	VFA	0.9964	RPA	0.5729	RCA	0.5866

Epoch 11
-------------------------------2021-07-11 23:29:40.479069
Avg loss: 0.8390  [ 1600/24705]
Avg loss: 0.9714  [ 3200/24705]
Avg loss: 1.0457  [ 4800/24705]
Avg loss: 0.8687  [ 6400/24705]
Avg loss: 0.9386  [ 8000/24705]
Avg loss: 1.1700  [ 9600/24705]
Avg loss: 0.7119  [11200/24705]
Avg loss: 1.1661  [12800/24705]
Avg loss: 0.6855  [14400/24705]
Avg loss: 0.5629  [16000/24705]
Avg loss: 0.7734  [17600/24705]
Avg loss: 0.7492  [19200/24705]
Avg loss: 0.7062  [20800/24705]
Avg loss: 0.9148  [22400/24705]
Avg loss: 1.2204  [24000/24705]
Adjusting learning rate of group 0 to 5.0630e-07.
Test Error: Avg loss: 1.5597 

Test OA	0.4169	VR	1.0000	VFA	0.9962	RPA	0.5767	RCA	0.5898

[in epoch 11, OA got new best: from 0.41509010873764984 to 0.4168598553844454. Will save the model]
Epoch 12
-------------------------------2021-07-11 23:38:26.723610
Avg loss: 0.8625  [ 1600/24705]
Avg loss: 0.9250  [ 3200/24705]
Avg loss: 1.0046  [ 4800/24705]
Avg loss: 0.9788  [ 6400/24705]
Avg loss: 0.7356  [ 8000/24705]
Avg loss: 0.8113  [ 9600/24705]
Avg loss: 1.2091  [11200/24705]
Avg loss: 1.0932  [12800/24705]
Avg loss: 1.0492  [14400/24705]
Avg loss: 0.9360  [16000/24705]
Avg loss: 0.9950  [17600/24705]
Avg loss: 0.8320  [19200/24705]
Avg loss: 0.8353  [20800/24705]
Avg loss: 0.9276  [22400/24705]
Avg loss: 0.7293  [24000/24705]
Adjusting learning rate of group 0 to 4.7592e-07.
Test Error: Avg loss: 1.5533 

Test OA	0.4144	VR	1.0000	VFA	0.9957	RPA	0.5734	RCA	0.5868

Epoch 13
-------------------------------2021-07-11 23:47:02.253871
Avg loss: 0.7887  [ 1600/24705]
Avg loss: 0.8418  [ 3200/24705]
Avg loss: 1.4968  [ 4800/24705]
Avg loss: 0.7578  [ 6400/24705]
Avg loss: 0.5200  [ 8000/24705]
Avg loss: 0.8826  [ 9600/24705]
Avg loss: 0.7700  [11200/24705]
Avg loss: 1.2406  [12800/24705]
Avg loss: 1.1758  [14400/24705]
Avg loss: 0.8810  [16000/24705]
Avg loss: 0.8531  [17600/24705]
Avg loss: 0.8393  [19200/24705]
Avg loss: 1.2207  [20800/24705]
Avg loss: 1.0235  [22400/24705]
Avg loss: 1.0461  [24000/24705]
Adjusting learning rate of group 0 to 4.4737e-07.
Test Error: Avg loss: 1.5521 

Test OA	0.4160	VR	1.0000	VFA	0.9965	RPA	0.5758	RCA	0.5893

Epoch 14
-------------------------------2021-07-11 23:55:34.896060
Avg loss: 0.7154  [ 1600/24705]
Avg loss: 0.8686  [ 3200/24705]
Avg loss: 0.8289  [ 4800/24705]
Avg loss: 1.0451  [ 6400/24705]
Avg loss: 1.1523  [ 8000/24705]
Avg loss: 0.8984  [ 9600/24705]
Avg loss: 1.0567  [11200/24705]
Avg loss: 0.9125  [12800/24705]
Avg loss: 0.7738  [14400/24705]
Avg loss: 0.9281  [16000/24705]
Avg loss: 1.0682  [17600/24705]
Avg loss: 0.8144  [19200/24705]
Avg loss: 0.5946  [20800/24705]
Avg loss: 0.9209  [22400/24705]
Avg loss: 0.8528  [24000/24705]
Adjusting learning rate of group 0 to 4.2052e-07.
Test Error: Avg loss: 1.5288 

Test OA	0.4190	VR	1.0000	VFA	0.9957	RPA	0.5806	RCA	0.5941

[in epoch 14, OA got new best: from 0.4168598553844454 to 0.41901942926533087. Will save the model]
Epoch 15
-------------------------------2021-07-12 00:04:06.308748
Avg loss: 0.6953  [ 1600/24705]
Avg loss: 0.7864  [ 3200/24705]
Avg loss: 0.8810  [ 4800/24705]
Avg loss: 0.9425  [ 6400/24705]
Avg loss: 0.9442  [ 8000/24705]
Avg loss: 1.0106  [ 9600/24705]
Avg loss: 0.8856  [11200/24705]
Avg loss: 0.7524  [12800/24705]
Avg loss: 1.0084  [14400/24705]
Avg loss: 0.7305  [16000/24705]
Avg loss: 0.8572  [17600/24705]
Avg loss: 1.0490  [19200/24705]
Avg loss: 1.0133  [20800/24705]
Avg loss: 0.7652  [22400/24705]
Avg loss: 0.8820  [24000/24705]
Adjusting learning rate of group 0 to 3.9529e-07.
Test Error: Avg loss: 1.5803 

Test OA	0.4138	VR	1.0000	VFA	0.9963	RPA	0.5718	RCA	0.5851

Epoch 16
-------------------------------2021-07-12 00:12:36.433225
Avg loss: 1.0778  [ 1600/24705]
Avg loss: 0.9977  [ 3200/24705]
Avg loss: 0.8686  [ 4800/24705]
Avg loss: 1.0545  [ 6400/24705]
Avg loss: 0.9793  [ 8000/24705]
Avg loss: 0.7799  [ 9600/24705]
Avg loss: 0.7170  [11200/24705]
Avg loss: 1.1448  [12800/24705]
Avg loss: 0.8886  [14400/24705]
Avg loss: 1.1045  [16000/24705]
Avg loss: 0.8624  [17600/24705]
Avg loss: 0.8027  [19200/24705]
Avg loss: 1.0769  [20800/24705]
Avg loss: 0.7337  [22400/24705]
Avg loss: 1.1035  [24000/24705]
Adjusting learning rate of group 0 to 3.7157e-07.
Test Error: Avg loss: 1.5438 

Test OA	0.4183	VR	1.0000	VFA	0.9966	RPA	0.5788	RCA	0.5912

Epoch 17
-------------------------------2021-07-12 00:21:07.885125
Avg loss: 1.2110  [ 1600/24705]
Avg loss: 0.9165  [ 3200/24705]
Avg loss: 0.6512  [ 4800/24705]
Avg loss: 0.8383  [ 6400/24705]
Avg loss: 0.7848  [ 8000/24705]
Avg loss: 0.5821  [ 9600/24705]
Avg loss: 0.7020  [11200/24705]
Avg loss: 1.0349  [12800/24705]
Avg loss: 0.7793  [14400/24705]
Avg loss: 0.6044  [16000/24705]
Avg loss: 0.9958  [17600/24705]
Avg loss: 0.5638  [19200/24705]
Avg loss: 0.8144  [20800/24705]
Avg loss: 0.6500  [22400/24705]
Avg loss: 1.0702  [24000/24705]
Adjusting learning rate of group 0 to 3.4928e-07.
Test Error: Avg loss: 1.5685 

Test OA	0.4197	VR	1.0000	VFA	0.9960	RPA	0.5808	RCA	0.5936

[in epoch 17, OA got new best: from 0.41901942926533087 to 0.41972318816581106. Will save the model]
Epoch 18
-------------------------------2021-07-12 00:29:38.889319
Avg loss: 0.6589  [ 1600/24705]
Avg loss: 0.8975  [ 3200/24705]
Avg loss: 0.8800  [ 4800/24705]
Avg loss: 0.7650  [ 6400/24705]
Avg loss: 0.6359  [ 8000/24705]
Avg loss: 1.0040  [ 9600/24705]
Avg loss: 0.6662  [11200/24705]
Avg loss: 0.9276  [12800/24705]
Avg loss: 0.6323  [14400/24705]
Avg loss: 1.1072  [16000/24705]
Avg loss: 0.7369  [17600/24705]
Avg loss: 0.7560  [19200/24705]
Avg loss: 0.6776  [20800/24705]
Avg loss: 0.5632  [22400/24705]
Avg loss: 0.8157  [24000/24705]
Adjusting learning rate of group 0 to 3.2832e-07.
Test Error: Avg loss: 1.5441 

Test OA	0.4142	VR	1.0000	VFA	0.9968	RPA	0.5755	RCA	0.5879

Epoch 19
-------------------------------2021-07-12 00:38:10.771600
Avg loss: 0.6380  [ 1600/24705]
Avg loss: 0.6976  [ 3200/24705]
Avg loss: 1.3088  [ 4800/24705]
Avg loss: 0.7105  [ 6400/24705]
Avg loss: 1.0059  [ 8000/24705]
Avg loss: 0.9211  [ 9600/24705]
Avg loss: 0.8835  [11200/24705]
Avg loss: 0.7514  [12800/24705]
Avg loss: 0.7724  [14400/24705]
Avg loss: 0.7078  [16000/24705]
Avg loss: 0.8199  [17600/24705]
Avg loss: 0.6406  [19200/24705]
Avg loss: 0.6873  [20800/24705]
Avg loss: 0.5161  [22400/24705]
Avg loss: 0.5452  [24000/24705]
Adjusting learning rate of group 0 to 3.0862e-07.
Test Error: Avg loss: 1.5365 

Test OA	0.4192	VR	1.0000	VFA	0.9963	RPA	0.5815	RCA	0.5944

Epoch 20
-------------------------------2021-07-12 00:46:41.329984
Avg loss: 0.6485  [ 1600/24705]
Avg loss: 0.6776  [ 3200/24705]
Avg loss: 0.6727  [ 4800/24705]
Avg loss: 0.8533  [ 6400/24705]
Avg loss: 0.8297  [ 8000/24705]
Avg loss: 0.9098  [ 9600/24705]
Avg loss: 0.7935  [11200/24705]
Avg loss: 0.7896  [12800/24705]
Avg loss: 0.9700  [14400/24705]
Avg loss: 0.6123  [16000/24705]
Avg loss: 0.8191  [17600/24705]
Avg loss: 0.8905  [19200/24705]
Avg loss: 0.8394  [20800/24705]
Avg loss: 0.8733  [22400/24705]
Avg loss: 0.9459  [24000/24705]
Adjusting learning rate of group 0 to 2.9011e-07.
Test Error: Avg loss: 1.5455 

Test OA	0.4204	VR	1.0000	VFA	0.9966	RPA	0.5822	RCA	0.5950

[in epoch 20, OA got new best: from 0.41972318816581106 to 0.4204200474692277. Will save the model]
Done!
