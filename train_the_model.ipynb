{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "refined-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import random\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import argparse, os, math\n",
    "\n",
    "import data_generator\n",
    "import hparams\n",
    "import model_unet\n",
    "import numpy as np\n",
    "import loss_function\n",
    "import utils\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-connecticut",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# argparse\n",
    "save_dir = None\n",
    "lr = 1e-4\n",
    "saved_model_path = None\n",
    "epochs = 0\n",
    "epochs_finished = 0\n",
    "num_floor = -1\n",
    "BATCH_SIZE = 16\n",
    "overlap = 4\n",
    "threshold = 0.05\n",
    "\n",
    "print('--------------ArgParse--------------')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-d', '--save_dir', help='ÁõÆÊ†áÂ≠òÂÇ®ÁõÆÂΩï')\n",
    "parser.add_argument('-s', '--saved_model', help='‰ª•ËÆ≠ÁªÉËøáÁöÑÊ®°Âûã')\n",
    "parser.add_argument('--lr', type=float, help='Â≠¶‰π†Áéá')\n",
    "parser.add_argument('-e', '--epochs', type=int, help='ÊúâÂá†‰∏™epoch')\n",
    "# parser.add_argument('--epochs_finished', type=int, help='Â∑≤ÁªèÂÆåÊàê‰∫ÜÂá†‰∏™epoch')\n",
    "parser.add_argument('-f', '--out_floor', type=int, help='ËæìÂá∫Âú®Á¨¨Âá†Â±Ç(0Ôºå1Ôºå2Ôºå3)')\n",
    "parser.add_argument('-g', '--gpu', help='Ë¶ÅÁî®ÁöÑgpuÂè∑')\n",
    "parser.add_argument('-b', '--batch_size', type=int, help='batch_size')\n",
    "parser.add_argument('-o', '--overlap', type=int, help='ÂàáÂá∫ËÆ≠ÁªÉÊï∞ÊçÆÊó∂ÔºåË∑≥Ê≠•Âç†ÂÖ®ÈÉ®ÈïøÂ∫¶ÁöÑÂá†ÂàÜ‰πã‰∏Ä')\n",
    "parser.add_argument('-t','--threshold', type=float, help='ÁîüÊàêÁªìÊûúÁî®ÁöÑÈòàÂÄº')\n",
    "parser.add_argument('--loss', type=int, help='ÊçüÂ§±ÂáΩÊï∞')\n",
    "parser.add_argument('--vt', help='È™åËØÅ/ÊµãËØïÈõÜ')\n",
    "parser.add_argument('--label', help='labelÁöÑÁ±ªÂûã')\n",
    "parser.add_argument('--fold', help='foldÁöÑÁ±ªÂûã')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "assert args.save_dir != None, ('ËØ∑ËæìÂÖ•Â≠òÂÇ®ÁõÆÂΩï')\n",
    "if not os.path.exists(args.save_dir):\n",
    "    print(f'Save_dir {args.save_dir} does not exist. Will create one.')\n",
    "    save_dir = args.save_dir\n",
    "    os.mkdir(save_dir)\n",
    "else:\n",
    "    print(f'Save_dir {args.save_dir} already exist. Will save to this directory.')\n",
    "    save_dir = args.save_dir\n",
    "\n",
    "\n",
    "if args.saved_model == None:\n",
    "    print('Don\\'t use saved model, train from scratch')\n",
    "else:\n",
    "    print(f'Use saved model[{args.saved_model}], train from it')\n",
    "saved_model_path = args.saved_model\n",
    "\n",
    "if args.lr == None:\n",
    "    print('Using default lr=1e-4')\n",
    "else:\n",
    "    lr = args.lr\n",
    "    print(f'Using lr from command: {lr}')\n",
    "\n",
    "assert args.epochs != None, ('ËØ∑ËæìÂÖ•epochsÊï∞')\n",
    "epochs = args.epochs\n",
    "\n",
    "assert args.out_floor != None, ('ËØ∑ËæìÂÖ•ËæìÂá∫ÁöÑÂ±ÇÊï∞')\n",
    "assert args.out_floor in [0,1,2,3], ('ËæìÂÖ•ÁöÑÂ±ÇÊï∞ÂøÖÈ°ª‰∏∫0 1 2 3‰πã‰∏Ä')\n",
    "num_floor = args.out_floor\n",
    "\n",
    "assert args.gpu != None, ('ËØ∑ËæìÂÖ•Ë¶ÅÁî®ÁöÑgpuÂè∑')\n",
    "device_ids = list(map(lambda x: int(x), args.gpu.split(',')))\n",
    "print(f'using device_ids: {device_ids}')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "print(f'device count: {torch.cuda.device_count()}')\n",
    "print(f'current device: {torch.cuda.current_device()}')\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "if args.batch_size == None:\n",
    "    print(f'using default batch_size {BATCH_SIZE}')\n",
    "else:\n",
    "    BATCH_SIZE = args.batch_size\n",
    "    print(f'using batch_size from command: {BATCH_SIZE}')\n",
    "    \n",
    "if args.overlap == None:\n",
    "    print(f'using default overlap {overlap}')\n",
    "else:\n",
    "    overlap = args.overlap\n",
    "    print(f'using overlap from command: {overlap}')\n",
    "overlap = 258//overlap\n",
    "\n",
    "if args.threshold == None:\n",
    "    print(f'using default threshold {threshold}')\n",
    "else:\n",
    "    threshold = args.threshold\n",
    "    print(f'using threshold from command: {threshold}')\n",
    "    \n",
    "if args.loss == 0:\n",
    "    loss_fn = loss_function.CrossEntropyLoss_Origin()\n",
    "elif args.loss == 1:\n",
    "    loss_fn = loss_function.CrossEntropyLoss_for_FA_CE()\n",
    "elif args.loss == 2:\n",
    "    loss_fn = loss_function.CrossEntropyLoss_for_FA_CE_VNV()\n",
    "elif args.loss == 3:\n",
    "    loss_fn = loss_function.CrossEntropyLoss_for_FA_CE_TF()\n",
    "elif args.loss == 4:\n",
    "    loss_fn = loss_function.CrossEntropyLoss_for_FA_CESQ_TF()\n",
    "else:\n",
    "    assert False, ('ÊçüÂ§±ÂáΩÊï∞‰ª£Âè∑‰∏çÂú®ËåÉÂõ¥ÂÜÖ')\n",
    "print(f'Using loss_function: {loss_fn.__class__.__name__}')\n",
    "\n",
    "assert args.vt[0]!=args.vt[1], ('È™åËØÅÈõÜ„ÄÅÊµãËØïÈõÜ‰∏çËÉΩ‰∏ÄÊ†∑')\n",
    "assert args.vt[0] in '0123456789', ('È™åËØÅÈõÜindex out of range')\n",
    "assert args.vt[1] in '0123456789', ('ÊµãËØïÈõÜindex out of range')\n",
    "valid_fold_index_list = [int(args.vt[0])]\n",
    "test_fold_index_list = [int(args.vt[1])]\n",
    "train_fold_index_list = [i for i in range(10) if (i not in valid_fold_index_list and i not in test_fold_index_list)]\n",
    "print(f'\\ttrain: {train_fold_index_list}\\n\\tvalid: {valid_fold_index_list}\\n\\ttest: {test_fold_index_list}')\n",
    "\n",
    "assert args.label in ['origin', 'real_one_hot', '3bin', '1bin'], ('labelÁ±ªÂûã‰∏çÂú®ËßÑÂÆöËåÉÂõ¥ÂÜÖ')\n",
    "label_kind = args.label\n",
    "print(f'label kind: {label_kind}')\n",
    "\n",
    "fold_version = args.fold\n",
    "print(f'fold version: {fold_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_unet.UNet()\n",
    "model = model.cuda()\n",
    "model = nn.DataParallel(model)\n",
    "# model = model.to(device)\n",
    "\n",
    "if saved_model_path != None:\n",
    "    print(f'loading model from {saved_model_path}...')\n",
    "    #model = torch.load(saved_model_path)\n",
    "    model.load_state_dict(torch.load(saved_model_path))\n",
    "else:\n",
    "    print('raw model')\n",
    "\n",
    "loss_fn = loss_fn.cuda()\n",
    "loss_fn = nn.DataParallel(loss_fn)\n",
    "# loss_fn = loss_fn.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\n",
    "scheduler_decay = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.94, verbose=True)\n",
    "scheduler_stop = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', threshold=1e-3, factor=-1, patience=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data, generate train/test_dataloader\n",
    "\n",
    "# prepare dataloader\n",
    "print(f'{datetime.datetime.now()} - Preparing train_dataloader...')\n",
    "train_dataloader = data_generator.source_index_to_chunk_list(source_list=train_fold_index_list, \n",
    "                                                             fold_version=fold_version,\n",
    "                                                             data_chunks_duration_in_bins=hparams.data_chunks_duration_in_bins,\n",
    "                                                             data_chunks_overlap_in_bins=overlap,\n",
    "                                                             label=label_kind)\n",
    "print(f'{datetime.datetime.now()} - Preparing valid_dataloader...')\n",
    "valid_dataloader = data_generator.source_index_to_chunk_list(source_list=valid_fold_index_list,\n",
    "                                                             fold_version=fold_version,\n",
    "                                                             data_chunks_duration_in_bins=hparams.data_chunks_duration_in_bins,\n",
    "                                                             data_chunks_overlap_in_bins=overlap,\n",
    "                                                             label=label_kind)\n",
    "print(f'{datetime.datetime.now()} - Preparing test_dataloader...')\n",
    "test_dataloader = data_generator.source_index_to_chunk_list(source_list=test_fold_index_list,\n",
    "                                                             fold_version=fold_version,\n",
    "                                                             data_chunks_duration_in_bins=hparams.data_chunks_duration_in_bins,\n",
    "                                                             data_chunks_overlap_in_bins=overlap,\n",
    "                                                             label=label_kind)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataloader, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataloader, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataloader, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-currency",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ‰∏Ä‰∏™epochÁöÑËÆ≠ÁªÉ+ÊµãËØï\n",
    "def train(dataloader, model, loss_fn, optimizer, scheduler, out_floor):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    batch_num = math.ceil(size/dataloader.batch_size)\n",
    "    loss_total = 0\n",
    "    \n",
    "    for batch, (X, y) in tqdm(enumerate(dataloader)): # ÊØèÊ¨°ËøîÂõû‰∏Ä‰∏™batch\n",
    "        # X, y = X.to(device), y.to(device)\n",
    "        X, y = X.cuda(device=device_ids[0]), y.cuda(device=device_ids[0])\n",
    "        # Compute prediction error\n",
    "        pred = model(X, out_floor)\n",
    "        \n",
    "        if out_floor == 0:\n",
    "            loss_gpus = loss_fn(pred, y, threshold)\n",
    "        else:\n",
    "            # downsample y\n",
    "            y_downsample = utils.downsample(y, out_floor)\n",
    "            loss_gpus = loss_fn(pred, y_downsample, threshold)\n",
    "            \n",
    "        # ÂØπ‰∫éÊüê‰∫õÁâπÊÆäÁöÑÊçüÂ§±ÂáΩÊï∞Ôºö\n",
    "        if args.loss in [2,3,4]:\n",
    "            loss = (loss_gpus[0].sum()+loss_gpus[2].sum())/(loss_gpus[1].sum()+loss_gpus[3].sum())\n",
    "        elif args.loss in [0,1]:\n",
    "            loss = loss_gpus.sum()\n",
    "            \n",
    "        if loss.item() != loss.item():\n",
    "            print('Train NaN!')\n",
    "            print(loss_gpus)\n",
    "            print('====================================================')\n",
    "            torch.save((X,y), os.path.join(save_dir, 'Xy_nan.pt'))\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, 'model_nan.pth'))\n",
    "            exit()\n",
    "            \n",
    "        loss_total += loss.item()\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch+1) % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"Avg loss: {loss:.4f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "    scheduler.step()\n",
    "    return loss_total/batch_num\n",
    "\n",
    "            \n",
    "def test(dataloader, model, loss_fn, out_floor):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        size = len(dataloader.dataset)\n",
    "        batch_num = math.ceil(size/dataloader.batch_size)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_loss_v, test_loss_nv = 0, 0\n",
    "        test_loss_f, test_loss_t = 0, 0\n",
    "        oa_avg, vr_avg, vfa_avg, rpa_avg, rca_avg = 0, 0, 0, 0, 0\n",
    "    \n",
    "    \n",
    "        for X, y in dataloader:\n",
    "            # X, y = X.to(device), y.to(device)\n",
    "            X, y = X.cuda(device=device_ids[0]), y.cuda(device=device_ids[0])\n",
    "            Xpred = model(X, out_floor)\n",
    "            Xout = utils.salience_to_output(Xpred.clone().detach(), threshold=threshold)\n",
    "            \n",
    "            if out_floor == 0:\n",
    "                loss = loss_fn(Xpred, y, threshold)\n",
    "                oa, vr, vfa, rpa, rca = evaluate.evaluate(Xout, y, out_floor)\n",
    "            else:\n",
    "                y_downsample = utils.downsample(y, out_floor)\n",
    "                loss = loss_fn(Xpred, y_downsample, threshold)\n",
    "                oa, vr, vfa, rpa, rca = evaluate.evaluate(Xout, y_downsample, out_floor)\n",
    "                \n",
    "            if args.loss == 2:\n",
    "                loss_gather = (loss[0].sum()+loss[2].sum())/(loss[1].sum()+loss[3].sum())\n",
    "                loss_v_gather = loss[0].sum()/loss[1].sum() if loss[1].sum() else loss[1].sum()*0\n",
    "                loss_nv_gather = loss[2].sum()/loss[3].sum() if loss[3].sum() else loss[3].sum()*0\n",
    "                test_loss_v += loss_v_gather.item()\n",
    "                test_loss_nv += loss_nv_gather.item()\n",
    "            elif args.loss in [3,4]:\n",
    "                loss_gather = (loss[0].sum()+loss[2].sum())/(loss[1].sum()+loss[3].sum())\n",
    "                loss_f_gather = loss[0].sum()/loss[1].sum() if loss[1].sum() else loss[1].sum()*0\n",
    "                loss_t_gather = loss[2].sum()/loss[3].sum() if loss[3].sum() else loss[3].sum()*0\n",
    "                test_loss_f += loss_f_gather.item()\n",
    "                test_loss_t += loss_t_gather.item()\n",
    "            elif args.loss in [0,1]:\n",
    "                loss_gather = loss.sum()\n",
    "                \n",
    "            if loss_gather.item() != loss_gather.item():\n",
    "                print('Test NaN!')\n",
    "                print(loss)\n",
    "                print('====================================================')\n",
    "                torch.save((X,y), os.path.join(save_dir, 'Xy_nan.pt'))\n",
    "                torch.save(model.state_dict(), os.path.join(save_dir, 'model_nan.pth'))\n",
    "                exit()\n",
    "            \n",
    "            test_loss += loss_gather.item()\n",
    "            \n",
    "            \n",
    "            oa_avg += oa\n",
    "            vr_avg += vr\n",
    "            vfa_avg += vfa\n",
    "            rpa_avg += rpa\n",
    "            rca_avg += rca\n",
    "            \n",
    "    test_loss /= batch_num # ÊØèÂº†ÂõæÁöÑloss\n",
    "    test_loss_v /= batch_num\n",
    "    test_loss_nv /= batch_num\n",
    "    test_loss_f /= batch_num\n",
    "    test_loss_t /= batch_num\n",
    "    \n",
    "    oa_avg /= batch_num\n",
    "    vr_avg /= batch_num\n",
    "    vfa_avg /= batch_num\n",
    "    rpa_avg /= batch_num\n",
    "    rca_avg /= batch_num\n",
    "    \n",
    "    print(f\"Test Error: Avg loss: {test_loss:.4f} \\n\")\n",
    "    print(f\"Test OA\\t{oa_avg:.4f}\\tVR\\t{vr_avg:.4f}\\tVFA\\t{vfa_avg:.4f}\\tRPA\\t{rpa_avg:.4f}\\tRCA\\t{rca_avg:.4f}\\n\")\n",
    "    \n",
    "    if args.loss in [0,1,2]:\n",
    "        return (test_loss, test_loss_v, test_loss_nv), oa_avg, vr_avg, vfa_avg, rpa_avg, rca_avg\n",
    "    elif args.loss in [3,4]:\n",
    "        return (test_loss, test_loss_f, test_loss_t), oa_avg, vr_avg, vfa_avg, rpa_avg, rca_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ËÆ≠ÁªÉÊ®°Âûãüåü\n",
    "# Â§ö‰∏™epochËÆ≠ÁªÉÔºåÊØè‰∏™epochÂêéÂú®È™åËØÅÈõÜ‰∏äÊµãËØï\n",
    "\n",
    "valid_oa_list = []\n",
    "test_oa_list = []\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "valid_loss_v_list = []\n",
    "valid_loss_nv_list = []\n",
    "test_loss_v_list = []\n",
    "test_loss_nv_list = []\n",
    "\n",
    "valid_loss_f_list = []\n",
    "valid_loss_t_list = []\n",
    "test_loss_f_list = []\n",
    "test_loss_t_list = []\n",
    "\n",
    "best_oa = 0\n",
    "\n",
    "_, oa, _, _, _, _ = test(valid_dataloader, model, loss_fn, num_floor)\n",
    "print(f'È™åËØÅÈõÜÂéüÂßãOA: {oa:.4f}.')\n",
    "best_oa = oa\n",
    "\n",
    "for t in range(epochs_finished, epochs_finished+epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------{datetime.datetime.now()}\")\n",
    "    train_loss = train(train_dataloader, model, loss_fn, optimizer, scheduler_decay, num_floor)\n",
    "    valid_loss, oa, _, _, _, _ = test(valid_dataloader, model, loss_fn, num_floor)\n",
    "    test_loss, test_oa, _, _, _, _ = test(test_dataloader, model, loss_fn, num_floor)\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_oa_list.append(oa)\n",
    "    test_oa_list.append(test_oa)\n",
    "    if args.loss in [0,1]:\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        test_loss_list.append(test_loss)\n",
    "        scheduler_stop.step(valid_loss)\n",
    "    elif args.loss == 2:\n",
    "        valid_loss_list.append(valid_loss[0])\n",
    "        valid_loss_v_list.append(valid_loss[1])\n",
    "        valid_loss_nv_list.append(valid_loss[2])\n",
    "        scheduler_stop.step(valid_loss[0])\n",
    "        test_loss_list.append(test_loss[0])\n",
    "        test_loss_v_list.append(test_loss[1])\n",
    "        test_loss_nv_list.append(test_loss[2])\n",
    "    elif args.loss in [3,4]:\n",
    "        valid_loss_list.append(valid_loss[0])\n",
    "        valid_loss_f_list.append(valid_loss[1])\n",
    "        valid_loss_t_list.append(valid_loss[2])\n",
    "        scheduler_stop.step(valid_loss[0])\n",
    "        test_loss_list.append(test_loss[0])\n",
    "        test_loss_f_list.append(test_loss[1])\n",
    "        test_loss_t_list.append(test_loss[2])\n",
    "    \n",
    "    if optimizer.state_dict()['param_groups'][0]['lr']<=0:\n",
    "        print(f'Early stop after {t+1} epochs.')\n",
    "        break\n",
    "    \n",
    "    if args.loss in [0,1]:\n",
    "        plt.plot(range(1,len(train_loss_list)+1), train_loss_list, 'y')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_list, 'm')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_list, 'r')\n",
    "        plt.plot(range(1, len(valid_oa_list)+1), valid_oa_list, 'b')\n",
    "        plt.plot(range(1, len(test_oa_list)+1), test_oa_list, 'b--')\n",
    "        plt.legend(['train loss', 'valid loss', 'test_loss','valid acc','test acc'])\n",
    "    elif args.loss == 2:\n",
    "        plt.plot(range(1,len(train_loss_list)+1), train_loss_list, 'y')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_list, 'm')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_v_list, 'm--')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_nv_list, 'm-.')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_list, 'r')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_v_list, 'r--')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_nv_list, 'r-.')\n",
    "        plt.plot(range(1, len(valid_oa_list)+1), valid_oa_list, 'b')\n",
    "        plt.plot(range(1, len(test_oa_list)+1), test_oa_list, 'b--')\n",
    "        plt.legend(['train loss', 'valid loss', 'valid loss(V)', 'valid loss(NV)', 'test loss', 'test loss(V)', 'test loss(NV)','valid acc','test acc'])\n",
    "    elif args.loss in [3,4]:\n",
    "        plt.plot(range(1,len(train_loss_list)+1), train_loss_list, 'y')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_list, 'm')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_f_list, 'm--')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_t_list, 'm-.')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_list, 'r')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_f_list, 'r--')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_t_list, 'r-.')\n",
    "        plt.plot(range(1, len(valid_oa_list)+1), valid_oa_list, 'b')\n",
    "        plt.plot(range(1, len(test_oa_list)+1), test_oa_list, 'b--')\n",
    "        plt.legend(['train loss', 'valid loss', 'valid loss(F)', 'valid loss(T)', 'test loss', 'test loss(F)', 'test loss(T)','valid acc','test acc'])\n",
    "    \n",
    "    plt.savefig(os.path.join(save_dir, 'loss.png'))\n",
    "    \n",
    "    # ‰øùÂ≠òÊúÄ‰ºòÊ®°Âûã\n",
    "    if oa > best_oa:\n",
    "        with torch.no_grad():\n",
    "            print(f'[in epoch {t+1}, OA got new best: from {best_oa:.4f} to {oa:.4f}. Will save the model]')\n",
    "            best_oa = oa\n",
    "            # torch.save(model, os.path.join(save_dir, f'model_floor{num_floor}_best.pth'))\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, f'model_floor{num_floor}_best.pth'))\n",
    "    \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
