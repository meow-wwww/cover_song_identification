{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "voluntary-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "\n",
    "from hpcp_loader_for_softdtw import *\n",
    "from torch.utils.data import DataLoader\n",
    "import models.BaseSPPNet as models\n",
    "# reload(models)\n",
    "from config import DefaultConfig, opt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from utility import *\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parallel.data_parallel import DataParallel\n",
    "from torch.nn import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import resource\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "## rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "## torch.backends.cudnn.benchmark = True  # cudnn有很多种并行计算卷积的算法，\n",
    "## resource.setrlimit(resource.RLIMIT_NOFILE, (2048, rlimit[1]))\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "device_ids = [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "egyptian-ordinance",
   "metadata": {
    "code_folding": [
     55,
     57,
     78,
     88,
     92,
     106,
     108,
     125
    ]
   },
   "outputs": [],
   "source": [
    "def neuralwarp_train(kwargs):\n",
    "    # 多尺度图片训练 396+\n",
    "\n",
    "    print(kwargs)\n",
    "\n",
    "    with open(kwargs['params']) as f:\n",
    "        params = json.load(f)\n",
    "    if kwargs['manner'] == 'train':\n",
    "        params['is_train'] = True\n",
    "    else:\n",
    "        params['is_train'] = False\n",
    "    params['batch_size'] = kwargs['batch_size']\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"-------------------Parallel_GPU_Train--------------------------\")\n",
    "        parallel = True\n",
    "    else:\n",
    "        print(\"------------------Single_GPU_Train----------------------\")\n",
    "        parallel = False\n",
    "    opt.feature = 'cqt'\n",
    "    opt.notes = 'SoftDTW'\n",
    "    opt.model = 'SoftDTW'\n",
    "    opt.batch_size = 'batch_size'\n",
    "    opt._parse(kwargs) # opt.model = NeuralDTW_CNN_Mask_dilation_SPP6\n",
    "    model = getattr(models, opt.model)(params)\n",
    "\n",
    "    p = 'check_points/' + model.model_name + opt.notes\n",
    "    if kwargs['model'] == 'NeuralDTW_CNN_Mask_dilation_SPP':\n",
    "        f = os.path.join(p, \"0704_19:58:25.pth\")\n",
    "    elif kwargs['model'] == 'NeuralDTW_CNN_Mask_dilation_SPP2':\n",
    "        f = os.path.join(p, \"0806_10:01:20.pth\")\n",
    "    elif kwargs['model'] == 'NeuralDTW_CNN_Mask_dilation':\n",
    "        f = os.path.join(p, \"0704_06:40:41.pth\")\n",
    "    elif kwargs['model'] == 'NeuralDTW_CNN_Mask_dilation_SPP5':\n",
    "        f = os.path.join(p, '0819_12:54:27.pth')\n",
    "    elif kwargs['model'] == 'NeuralDTW_CNN_Mask_dilation_SPP6':\n",
    "        f = os.path.join(p, '0819_01:03:39.pth')\n",
    "    elif kwargs['model'] == 'NeuralDTW_2':\n",
    "        f = os.path.join(p, '0907_09:58:52.pth')\n",
    "    elif kwargs['model'] == 'NeuralDTW_seq_vector2':\n",
    "        f = os.path.join(p, '0921_09:40:49.pth')\n",
    "    opt.load_model_path = f\n",
    "    if kwargs['model'] != 'NeuralDTW' and kwargs['manner'] != 'train':\n",
    "        if opt.load_latest is True:\n",
    "            model.load_latest(opt.notes)\n",
    "        elif opt.load_model_path:\n",
    "            print(\"load_model:\", opt.load_model_path)\n",
    "            model.load(opt.load_model_path)\n",
    "\n",
    "    if parallel == True:\n",
    "        model = DataParallel(model)\n",
    "    model.to(opt.device)\n",
    "    torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "    \n",
    "    # step2: data\n",
    "    out_length = 400\n",
    "    if kwargs['model'] == 'NeuralDTW_CNN_Mask_300':\n",
    "        out_length = 300\n",
    "    if kwargs['model'] == 'NeuralDTW_CNN_Mask_spp':\n",
    "        train_data0 = triplet_CQT(out_length=200, is_label=kwargs['is_label'], is_random=kwargs['is_random'])\n",
    "        train_data1 = triplet_CQT(out_length=300, is_label=kwargs['is_label'], is_random=kwargs['is_random'])\n",
    "        train_data2 = triplet_CQT(out_length=400, is_label=kwargs['is_label'], is_random=kwargs['is_random'])\n",
    "    else:\n",
    "        train_data0 = triplet_CQT(out_length=400, is_label=kwargs['is_label'], is_random=kwargs['is_random'])\n",
    "        train_data1 = triplet_CQT(out_length=400, is_label=kwargs['is_label'], is_random=kwargs['is_random'])\n",
    "        train_data2 = triplet_CQT(out_length=400, is_label=kwargs['is_label'], is_random=kwargs['is_random'])\n",
    "#     val_data80 = CQT('songs80', out_length=kwargs['test_length'])\n",
    "#     val_data = CQT('songs350', out_length=kwargs['test_length'])\n",
    "    # val_data80 =CQT_cut_test('songs80', out_length=None)\n",
    "    # val_data = CQT_cut_test('songs350', out_length=None)\n",
    "    # val_data_marukars = CQT('Mazurkas',out_length=kwargs['test_length'])\n",
    "    # val_song2000 = CQT('test',out_length=kwargs['test_length'])\n",
    "    train_dataloader0 = DataLoader(train_data0, opt.batch_size, shuffle=True, num_workers=opt.num_workers)\n",
    "    train_dataloader1 = DataLoader(train_data1, opt.batch_size, shuffle=True, num_workers=opt.num_workers)\n",
    "    train_dataloader2 = DataLoader(train_data2, opt.batch_size, shuffle=True, num_workers=opt.num_workers)\n",
    "#     val_dataloader80 = DataLoader(val_data80, 1, shuffle=False, num_workers=1)\n",
    "#     val_dataloader = DataLoader(val_data, 1, shuffle=False, num_workers=1)\n",
    "    # val_dataloader_marukars = DataLoader(val_data_marukars,300, shuffle=False, num_workers=1)\n",
    "    # val_dataloader2000 = DataLoader(val_song2000,300,shuffle=False,num_workers=16)\n",
    "    if kwargs['manner'] == 'test':\n",
    "\n",
    "        val_data80_1 = CQT('songs80', out_length=kwargs['test_length'])\n",
    "        val_data_1 = CQT('songs350', out_length=kwargs['test_length'])\n",
    "        val_dataloader80_1 = DataLoader(val_data80_1, 1, shuffle=False, num_workers=1)\n",
    "        val_dataloader_1 = DataLoader(val_data_1, 1, shuffle=False, num_workers=1)\n",
    "        map1 = val_quick(model, val_dataloader_1)\n",
    "        map2 = val_quick(model, val_dataloader80_1)\n",
    "        print(map1)\n",
    "        print(map2)\n",
    "    elif kwargs['manner'] == 'visualize':\n",
    "        # visualize(model, val_dataloader80)\n",
    "        # test_visualize(model)\n",
    "        vis(model, val_dataloader80)\n",
    "    elif kwargs['manner'] == 'mul_test':\n",
    "        p = 'check_points/' + model.model_name + opt.notes\n",
    "        l = sorted(os.listdir(p))[: 20]\n",
    "        best_MAP, MAP = 0, 0\n",
    "        for f in l:\n",
    "            f = os.path.join(p, f)\n",
    "            model.load(f)\n",
    "            model.to(opt.device)\n",
    "            MAP += val_slow_batch(model, val_dataloader, batch=400, is_dis=kwargs['zo'])\n",
    "            MAP += val_slow_batch(model, val_dataloader80, batch=400, is_dis=kwargs['zo'])\n",
    "            if MAP > best_MAP:\n",
    "                print('--best result--')\n",
    "                best_MAP = MAP\n",
    "            MAP = 0\n",
    "    elif kwargs['manner'] == \"test_covers80\":\n",
    "        test_covers80(model, val_dataloader80)\n",
    "    elif kwargs['manner'] == 'tempo_change_test':\n",
    "        val_data08 = CQT_test('tempo08', out_length=kwargs['test_length'])\n",
    "        val_data09 = CQT_test('tempo09', out_length=kwargs['test_length'])\n",
    "        val_data11 = CQT_test('tempo11', out_length=kwargs['test_length'])\n",
    "        val_data12 = CQT_test('tempo12', out_length=kwargs['test_length'])\n",
    "        val_dataloader08 = DataLoader(val_data08, 100, shuffle=False, num_workers=1)\n",
    "        val_dataloader09 = DataLoader(val_data09, 100, shuffle=False, num_workers=1)\n",
    "        val_dataloader11 = DataLoader(val_data11, 100, shuffle=False, num_workers=1)\n",
    "        val_dataloader12 = DataLoader(val_data12, 100, shuffle=False, num_workers=1)\n",
    "        print(\"tempo_change_08:\")\n",
    "        val_slow_batch_test(model, val_dataloader08, val_dataloader80, batch=100, is_dis=kwargs['zo'])\n",
    "        print(\"tempo_change_09:\")\n",
    "        val_slow_batch_test(model, val_dataloader09, val_dataloader80, batch=100, is_dis=kwargs['zo'])\n",
    "        print(\"tempo_change_11:\")\n",
    "        val_slow_batch_test(model, val_dataloader11, val_dataloader80, batch=100, is_dis=kwargs['zo'])\n",
    "        print(\"tempo_change_12:\")\n",
    "        val_slow_batch_test(model, val_dataloader12, val_dataloader80, batch=100, is_dis=kwargs['zo'])\n",
    "    elif kwargs['manner'] == 'key_change_test':\n",
    "        val_data6 = CQT_test('key_6', out_length=kwargs['test_length'])\n",
    "        val_datan6 = CQT_test('key_n6', out_length=kwargs['test_length'])\n",
    "        val_data12 = CQT_test('key_12', out_length=kwargs['test_length'])\n",
    "        val_datan12 = CQT_test('key_n12', out_length=kwargs['test_length'])\n",
    "        val_dataloader6 = DataLoader(val_data6, 100, shuffle=False, num_workers=1)\n",
    "        val_dataloadern6 = DataLoader(val_datan6, 100, shuffle=False, num_workers=1)\n",
    "        val_dataloader12 = DataLoader(val_data12, 100, shuffle=False, num_workers=1)\n",
    "        val_dataloadern12 = DataLoader(val_datan12, 100, shuffle=False, num_workers=1)\n",
    "        print(\"key_6:\")\n",
    "        val_slow_batch_test(model, val_dataloader6, val_dataloader80, batch=100, is_dis=kwargs['zo'])\n",
    "        print(\"key_n6:\")\n",
    "        val_slow_batch_test(model, val_dataloadern6, val_dataloader80, batch=100, is_dis=kwargs['zo'])\n",
    "        print(\"key_12:\")\n",
    "        val_slow_batch_test(model, val_dataloader12, val_dataloader80, batch=100, is_dis=kwargs['zo'])\n",
    "        print(\"key_n12:\")\n",
    "        val_slow_batch_test(model, val_dataloadern12, val_dataloader80, batch=100, is_dis=kwargs['zo'])\n",
    "    else: # 'train'\n",
    "        # step3: criterion and optimizer\n",
    "        be = torch.nn.BCELoss()\n",
    "\n",
    "        lr = opt.lr\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=opt.weight_decay)\n",
    "\n",
    "        # if parallel is True:\n",
    "        #     optimizer = torch.optim.Adam(model.module.parameters(), lr=lr, weight_decay=opt.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=10,\n",
    "                                                               verbose=True, min_lr=5e-6)\n",
    "        # step4: train\n",
    "        best_MAP = 0\n",
    "        for epoch in range(opt.max_epoch):\n",
    "            print(f'---------epoch {epoch}----------')\n",
    "            running_loss = 0\n",
    "            num = 0\n",
    "            for ii, ((a0, p0, n0, la0, lp0, ln0), (a1, p1, n1, la1, lp1, ln1), (a2, p2, n2, la2, lp2, ln2)) in tqdm(\n",
    "                    enumerate(zip(train_dataloader0, train_dataloader1, train_dataloader2))):\n",
    "                # for ii, (a2, p2, n2) in tqdm(enumerate(train_dataloader2)):\n",
    "                for flag in range(3):\n",
    "                    if flag == 0:\n",
    "                        a, p, n, la, lp, ln = a0, p0, n0, la0, lp0, ln0\n",
    "                    elif flag == 1:\n",
    "                        a, p, n, la, lp, ln = a1, p1, n1, la1, lp1, ln1\n",
    "                    else:\n",
    "                        a, p, n, la, lp, ln = a2, p2, n2, la2, lp2, ln2\n",
    "                    B, _, _, _ = a.shape\n",
    "                    if kwargs[\"zo\"] == True:\n",
    "                        target = torch.cat((torch.zeros(B), torch.ones(B))).cuda()\n",
    "                    else:\n",
    "                        target = torch.cat((torch.ones(B), torch.zeros(B))).cuda()\n",
    "                    # train model\n",
    "                    a = a.requires_grad_().to(opt.device)\n",
    "                    p = p.requires_grad_().to(opt.device)\n",
    "                    n = n.requires_grad_().to(opt.device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(a, p, n)\n",
    "                    pred = pred.squeeze(1)\n",
    "                    print(pred, target\n",
    "                         )\n",
    "                    loss = be(pred, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "                    num += a.shape[0]\n",
    "\n",
    "                if ii % 1 == 0 :\n",
    "                    print(f'num={num}')\n",
    "                    running_loss /= num\n",
    "                    print(\"train_loss:\", running_loss)\n",
    "\n",
    "#                     MAP = 0\n",
    "#                     print(\"Youtube350:\")\n",
    "#                     MAP += val_slow_batch(model, val_dataloader, batch=100, is_dis=kwargs['zo'])\n",
    "#                     print(\"CoverSong80:\")\n",
    "#                     MAP += val_slow_batch(model, val_dataloader80, batch=100, is_dis=kwargs['zo'])\n",
    "                    # print(\"Youtube350:\")\n",
    "                    # MAP += val_quick(model, val_dataloader)\n",
    "                    # print(\"CoverSong80:\")\n",
    "                    # MAP += val_quick(model, val_dataloader80)\n",
    "                    # print(\"Marukars:\")\n",
    "                    # MAP += val_slow_batch(model, val_dataloader_marukars, batch=100, is_dis=kwargs['zo'])\n",
    "#                     if MAP > best_MAP:\n",
    "#                         best_MAP = MAP\n",
    "#                         print('*****************BEST*****************')\n",
    "#                     if kwargs['save_model'] == True:\n",
    "#                         if parallel:\n",
    "#                             model.module.save(opt.notes)\n",
    "#                         else:\n",
    "#                             model.save(opt.notes)\n",
    "                    scheduler.step(running_loss)\n",
    "                    running_loss = 0\n",
    "                    num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-chuck",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kwargs = {'model': 'NeuralDTW_CNN_Mask_dilation_SPP6', 'num_workers': 16, 'batch_size': 5, 'is_label': True,\n",
    "              'is_random': False, 'notes': 'mask', 'save_model': True, 'manner': 'train',\n",
    "              'params': 'params/neuraldtw/mask0', 'test_length': 400, 'zo': False }\n",
    "neuralwarp_train(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-knitting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-oasis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data0 = triplet_CQT(out_length=400, is_label=True)\n",
    "train_dataloader0 = DataLoader(train_data0, 5, shuffle=True)\n",
    "\n",
    "for a, p, n, la, lp, ln in train_dataloader0:\n",
    "    break\n",
    "\n",
    "opt.model = 'NeuralDTW_CNN_Mask_dilation_SPP6'\n",
    "\n",
    "model = getattr(models, opt.model)(None)\n",
    "model.to('cuda')\n",
    "pass\n",
    "\n",
    "a = a.to('cuda')\n",
    "p = p.to('cuda')\n",
    "n = n.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-alberta",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-digit",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_quick(softdtw, dataloader):\n",
    "    # softdtw: model\n",
    "    softdtw.eval()\n",
    "    softdtw.model.eval()\n",
    "    labels = []\n",
    "    temp = []\n",
    "    count = -1\n",
    "    for ii, (data, label) in tqdm(enumerate(dataloader)):\n",
    "        labels.append(label)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    N = labels.shape[0] # 样本数\n",
    "    dis2d = np.zeros((N, N))\n",
    "    for ii, (data, label) in tqdm(enumerate(dataloader)):\n",
    "        data = data.cuda()\n",
    "        print(data.shape)\n",
    "        count += 1\n",
    "        if count == 0:\n",
    "            temp.append((data, count))\n",
    "        else:\n",
    "            for i in range(len(temp)):\n",
    "                dis = softdtw.multi_compute_s(data, temp[i][0]).data.cpu().numpy()\n",
    "                dis2d[temp[i][1]][count], dis2d[count][temp[i][1]] = -dis, -dis\n",
    "            temp.append((data, count))\n",
    "\n",
    "    MAP, top10, rank1 = calc_MAP(dis2d[0:labels.shape[0], 0:labels.shape[0]], labels)\n",
    "    print(MAP, top10, rank1)\n",
    "    softdtw.train()\n",
    "    softdtw.model.train()\n",
    "    return MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-diploma",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def neuralwarp_train_1(**kwargs):\n",
    "    # 多尺度图片训练 396+\n",
    "    # print(kwargs)\n",
    "    # print(\"Mask == 1\")\n",
    "\n",
    "    print(kwargs)\n",
    "\n",
    "    with open(kwargs['params']) as f:\n",
    "        params = json.load(f)\n",
    "    if kwargs['manner'] == 'train':\n",
    "        params['is_train'] = True\n",
    "    else:\n",
    "        params['is_train'] = False\n",
    "    params['batch_size'] = kwargs['batch_size']\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"-------------------Parallel_GPU_Train--------------------------\")\n",
    "        parallel = True\n",
    "    else:\n",
    "        print(\"------------------Single_GPU_Train----------------------\")\n",
    "        parallel = False\n",
    "    opt.feature = 'cqt'\n",
    "    opt.notes = 'SoftDTW'\n",
    "    opt.model = 'SoftDTW'\n",
    "    opt.batch_size = 'batch_size'\n",
    "    opt._parse(kwargs)\n",
    "    model = getattr(models, opt.model)(params)\n",
    "\n",
    "    p = 'check_points/' + model.model_name + opt.notes\n",
    "    f = os.path.join(p,\n",
    "                     \"0620_07:05:30.pth\")  # 使用Neural_dtw目前最优 0620_07:05:30.pth cover80 map:0.705113267654046 0.08125 7.96875\n",
    "\n",
    "    opt.load_model_path = f\n",
    "    if kwargs['model'] != 'NeuralDTW' and kwargs['manner'] != 'train':\n",
    "        if opt.load_latest is True:\n",
    "            model.load_latest(opt.notes)\n",
    "        elif opt.load_model_path:\n",
    "            print(\"load_model:\", opt.load_model_path)\n",
    "            model.load(opt.load_model_path)\n",
    "\n",
    "    if parallel == True:\n",
    "        model = DataParallel(model)\n",
    "    model.to(opt.device)\n",
    "    torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "    # step2: data\n",
    "    out_length = 400\n",
    "    train_data0 = triplet_CQT_test(out_length=300, is_label=kwargs['is_label'], is_random=kwargs['is_random'])\n",
    "    train_data1 = triplet_CQT_test(out_length=400, is_label=kwargs['is_label'], is_random=kwargs['is_random'])\n",
    "    train_data2 = triplet_CQT_test(out_length=500, is_label=kwargs['is_label'], is_random=kwargs['is_random'])\n",
    "    val_data80 = CQT_cut_test('songs80', out_length=None)\n",
    "    val_data = CQT_cut_test('songs350', out_length=None)\n",
    "    train_dataloader0 = DataLoader(train_data0, opt.batch_size, shuffle=True, num_workers=opt.num_workers)\n",
    "    train_dataloader1 = DataLoader(train_data1, opt.batch_size, shuffle=True, num_workers=opt.num_workers)\n",
    "    train_dataloader2 = DataLoader(train_data2, opt.batch_size, shuffle=True, num_workers=opt.num_workers)\n",
    "    val_dataloader80 = DataLoader(val_data80, 1, shuffle=False, num_workers=1)\n",
    "    val_dataloader = DataLoader(val_data, 1, shuffle=False, num_workers=1)\n",
    "    if kwargs['manner'] == 'test':\n",
    "\n",
    "        val_data80_1 = CQT_cut_test('songs80', out_length=kwargs['test_length'])\n",
    "        val_data_1 = CQT_cut_test('songs350', out_length=kwargs['test_length'])\n",
    "        val_dataloader80_1 = DataLoader(val_data80_1, 1, shuffle=False, num_workers=1)\n",
    "        val_dataloader_1 = DataLoader(val_data_1, 1, shuffle=False, num_workers=1)\n",
    "        val_quick(model, val_dataloader_1)\n",
    "        val_quick(model, val_dataloader80_1)\n",
    "\n",
    "    elif kwargs['manner'] == 'visualize':\n",
    "        # visualize(model, val_dataloader80)\n",
    "        test_visualize(model)\n",
    "    else:\n",
    "        # step3: criterion and optimizer\n",
    "        be = torch.nn.BCELoss()\n",
    "\n",
    "        lr = opt.lr\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=opt.weight_decay)\n",
    "\n",
    "        # if parallel is True:\n",
    "        #     optimizer = torch.optim.Adam(model.module.parameters(), lr=lr, weight_decay=opt.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=10,\n",
    "                                                               verbose=True, min_lr=5e-6)\n",
    "        # step4: train\n",
    "        best_MAP = 0\n",
    "        for epoch in range(opt.max_epoch):\n",
    "            running_loss = 0\n",
    "            num = 0\n",
    "            for ii, ((a0, p0, n0, la0, lp0, ln0), (a1, p1, n1, la1, lp1, ln1), (a2, p2, n2, la2, lp2, ln2)) in tqdm(\n",
    "                    enumerate(zip(train_dataloader0, train_dataloader1, train_dataloader2))):\n",
    "                # for ii, (a2, p2, n2) in tqdm(enumerate(train_dataloader2)):\n",
    "                for flag in range(3):\n",
    "                    if flag == 0:\n",
    "                        a, p, n, la, lp, ln = a0, p0, n0, la0, lp0, ln0\n",
    "                    elif flag == 1:\n",
    "                        a, p, n, la, lp, ln = a1, p1, n1, la1, lp1, ln1\n",
    "                    else:\n",
    "                        a, p, n, la, lp, ln = a2, p2, n2, la2, lp2, ln2\n",
    "                    B, _, _, _ = a.shape\n",
    "                    if kwargs[\"zo\"] == True:\n",
    "                        target = torch.cat((torch.zeros(B), torch.ones(B))).cuda()\n",
    "                    else:\n",
    "                        target = torch.cat((torch.ones(B), torch.zeros(B))).cuda()\n",
    "                    # train model\n",
    "                    a = a.requires_grad_().to(opt.device)\n",
    "                    p = p.requires_grad_().to(opt.device)\n",
    "                    n = n.requires_grad_().to(opt.device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    pred = model(a, p, n)\n",
    "                    pred = pred.squeeze(1)\n",
    "                    loss = be(pred, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item()\n",
    "                    num += a.shape[0]\n",
    "\n",
    "                if ii % 5000 == 0 and ii != 0:\n",
    "                    running_loss /= num\n",
    "                    print(\"train_loss:\", running_loss)\n",
    "\n",
    "#                     MAP = 0\n",
    "                    # print(\"Youtube350:\")\n",
    "                    # MAP += val_slow_batch(model, val_dataloader, batch=100, is_dis=kwargs['zo'])\n",
    "                    # print(\"CoverSong80:\")\n",
    "                    # MAP += val_slow_batch(model, val_dataloader80, batch=100, is_dis=kwargs['zo'])\n",
    "#                     print(\"Youtube350:\")\n",
    "#                     MAP += val_quick(model, val_dataloader)\n",
    "#                     print(\"CoverSong80:\")\n",
    "#                     MAP += val_quick(model, val_dataloader80)\n",
    "                    # print(\"Marukars:\")\n",
    "                    # MAP += val_slow_batch(model, val_dataloader_marukars, batch=100, is_dis=kwargs['zo'])\n",
    "#                     if MAP > best_MAP:\n",
    "#                         best_MAP = MAP\n",
    "#                         print('*****************BEST*****************')\n",
    "#                     if kwargs['save_model'] == True:\n",
    "#                         if parallel:\n",
    "#                             model.module.save(opt.notes)\n",
    "#                         else:\n",
    "#                             model.save(opt.notes)\n",
    "                    scheduler.step(running_loss)\n",
    "                    running_loss = 0\n",
    "                    num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-nigeria",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_slow(softdtw, dataloader, style='null'):\n",
    "    softdtw.eval()\n",
    "    softdtw.model.eval()\n",
    "\n",
    "    seqs, labels = [], []\n",
    "    for ii, (data, label) in tqdm(enumerate(dataloader)):\n",
    "        input = data.cuda()\n",
    "\n",
    "        seqs.append(input)\n",
    "        labels.append(label)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "\n",
    "    N = labels.shape[0]\n",
    "    if N == 350:\n",
    "        query_l = [i // 100 for i in range(100 * 100, 350 * 100)]\n",
    "        ref_l = [i for i in range(100)] * 250\n",
    "    else:\n",
    "        query_l = [i // N for i in range(N * N)]\n",
    "        ref_l = [i for i in range(N)] * N\n",
    "    dis2d = np.zeros((N, N))\n",
    "\n",
    "    for st in range(0, N * N if N != 350 else 100 * 250):\n",
    "        query = seqs[query_l[st]]\n",
    "        ref = seqs[ref_l[st]]\n",
    "        if style == 'min':\n",
    "            T = min(query.shape[1], ref.shape[1])\n",
    "            query, ref = query[:, :T, :], ref[:, :T, :]\n",
    "        # print(softdtw.metric(query, ref))\n",
    "        s = softdtw.multi_compute_s(query, ref).data.cpu().numpy()\n",
    "        i, j = query_l[st], ref_l[st]\n",
    "        dis2d[i, j], dis2d[j, i] = -s[0], -s[0]\n",
    "\n",
    "    if len(labels) == 350:\n",
    "        MAP, top10, rank1 = calc_MAP(dis2d, labels, [100, 350])\n",
    "    else:\n",
    "        MAP, top10, rank1 = calc_MAP(dis2d, labels)\n",
    "    print(MAP, top10, rank1)\n",
    "\n",
    "    softdtw.train()\n",
    "    softdtw.model.train()\n",
    "    return MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-basic",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_slow_batch(softdtw, dataloader, batch=200, is_dis='False'):\n",
    "    softdtw.eval()\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        softdtw.module.model.eval()\n",
    "    else:\n",
    "        softdtw.model.eval()\n",
    "    seqs, labels = [], []\n",
    "    for ii, (data, label) in tqdm(enumerate(dataloader)):\n",
    "        input = data.cuda()\n",
    "        # _, seq, _ = softdtw.model(input)\n",
    "        seqs.append(input)\n",
    "        labels.append(label)\n",
    "    seqs = torch.cat(seqs, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "\n",
    "    N = labels.shape[0]\n",
    "    if N == 350:\n",
    "        query_l = [i // 100 for i in range(100 * 100, 350 * 100)]\n",
    "        ref_l = [i for i in range(100)] * 250\n",
    "    else:\n",
    "        query_l = [i // N for i in range(N * N)]\n",
    "        ref_l = [i for i in range(N)] * N\n",
    "    dis2d = np.zeros((N, N))\n",
    "\n",
    "    N = N * N if N != 350 else 100 * 250\n",
    "    for st in range(0, N, batch):\n",
    "        fi = (st + batch) if st + batch <= N else N\n",
    "        query = seqs[query_l[st: fi], :, :]\n",
    "        ref = seqs[ref_l[st: fi], :, :]\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            s = softdtw.module.multi_compute_s(query, ref).data.cpu().numpy()\n",
    "        else:\n",
    "            s = softdtw.multi_compute_s(query, ref).data.cpu().numpy()\n",
    "        for k in range(st, fi):\n",
    "            i, j = query_l[k], ref_l[k]\n",
    "            # print(i, j)\n",
    "            if is_dis:\n",
    "                dis2d[i, j] = s[k - st]\n",
    "            else:\n",
    "                dis2d[i, j] = -s[k - st]\n",
    "\n",
    "    if len(labels) == 350:\n",
    "        MAP, top10, rank1 = calc_MAP(dis2d, labels, [100, 350])\n",
    "    else:\n",
    "        MAP, top10, rank1 = calc_MAP(dis2d, labels)\n",
    "    print(MAP, top10, rank1)\n",
    "\n",
    "    softdtw.train()\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        softdtw.module.model.train()\n",
    "    else:\n",
    "        softdtw.model.train()\n",
    "    return MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-punch",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_slow_batch_test(softdtw, dataloaderQ, dataloaderR, batch=200, is_dis='False'):\n",
    "    softdtw.eval()\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        softdtw.module.model.eval()\n",
    "    else:\n",
    "        softdtw.model.eval()\n",
    "    seqsQ, seqs, labels = [], [], []\n",
    "\n",
    "    for ii, (data, label) in tqdm(enumerate(dataloaderQ)):\n",
    "        input = data.cuda()\n",
    "        # _, seq, _ = softdtw.model(input)\n",
    "        seqsQ.append(input)\n",
    "\n",
    "        labels.append(label)\n",
    "    for ii, (data, label) in tqdm(enumerate(dataloaderR)):\n",
    "        input = data.cuda()\n",
    "        # _, seq, _ = softdtw.model(input)\n",
    "        seqs.append(input)\n",
    "    seqsQ = torch.cat(seqsQ, dim=0)\n",
    "    seqs = torch.cat(seqs, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "\n",
    "    N = labels.shape[0]\n",
    "    if N == 350:\n",
    "        query_l = [i // 100 for i in range(100 * 100, 350 * 100)]\n",
    "        ref_l = [i for i in range(100)] * 250\n",
    "    else:\n",
    "        query_l = [i // N for i in range(N * N)]\n",
    "        ref_l = [i for i in range(N)] * N\n",
    "    dis2d = np.zeros((N, N))\n",
    "\n",
    "    N = N * N if N != 350 else 100 * 250\n",
    "    for st in range(0, N, batch):\n",
    "        fi = (st + batch) if st + batch <= N else N\n",
    "        query = seqsQ[query_l[st: fi], :, :]\n",
    "        ref = seqs[ref_l[st: fi], :, :]\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            s = softdtw.module.multi_compute_s(query, ref).data.cpu().numpy()\n",
    "        else:\n",
    "            s = softdtw.multi_compute_s(query, ref).data.cpu().numpy()\n",
    "        for k in range(st, fi):\n",
    "            i, j = query_l[k], ref_l[k]\n",
    "            # print(i, j)\n",
    "            if is_dis:\n",
    "                dis2d[i, j] = s[k - st]\n",
    "            else:\n",
    "                dis2d[i, j] = -s[k - st]\n",
    "\n",
    "    if len(labels) == 350:\n",
    "        MAP, top10, rank1 = calc_MAP(dis2d, labels, [100, 350])\n",
    "    else:\n",
    "        MAP, top10, rank1 = calc_MAP(dis2d, labels)\n",
    "    print(MAP, top10, rank1)\n",
    "\n",
    "    softdtw.train()\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        softdtw.module.model.train()\n",
    "    else:\n",
    "        softdtw.model.train()\n",
    "    return MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import fire\n",
    "\n",
    "    fire.Fire()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
