{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "992eae5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import argparse, os, math\n",
    "import numpy as np\n",
    "from hpcp_loader_for_softdtw import *\n",
    "import models.BaseSPPNet as models\n",
    "from config import DefaultConfig, opt\n",
    "from utility import *\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import resource\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7083a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecae4d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = None\n",
    "saved_model_path = './experiment/0.2.2/latest.pth'\n",
    "lr = 1e-6\n",
    "weight_decay = 0\n",
    "num_workers = 0\n",
    "epochs = 100\n",
    "epochs_finished = 0\n",
    "BATCH_SIZE = 10\n",
    "device_ids = [0]\n",
    "datatype = 'multif0_avg5'\n",
    "train_scale = 'so_short'\n",
    "test_scale = 'so_short'\n",
    "test_source = 'gdoras_train'\n",
    "train_cut = 'front'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50031cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from ./experiment/0.2.2/latest.pth...\n"
     ]
    }
   ],
   "source": [
    "model = models.NeuralDTW_CNN_Mask_dilation_SPP6(None)\n",
    "model = model.cuda()\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "if saved_model_path != None:\n",
    "    print(f'loading model from {saved_model_path}...')\n",
    "    model.load_state_dict(torch.load(saved_model_path))\n",
    "\n",
    "loss_fn = nn.BCELoss() # loss_fn返回的值已经对每个样本做平均了\n",
    "loss_fn = loss_fn.cuda()\n",
    "loss_fn = nn.DataParallel(loss_fn)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=10,\n",
    "                                                               verbose=True, min_lr=5e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb99710",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# init\n",
    "from torch.nn import init\n",
    "#define the initial function to init the layer's parameters for the network\n",
    "\n",
    "def initNetParams(net):\n",
    "    '''Init net parameters.'''\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_uniform(m.weight)\n",
    "            if m.bias != None:\n",
    "                init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant(m.weight, 1)\n",
    "            init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.normal(m.weight, std=1e-3)\n",
    "            if m.bias != None:\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "initNetParams(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17549191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-12 00:00:55.092243 - Preparing train_dataloader...\n",
      "2021-10-12 00:00:55.094468 - Preparing test_dataloader...\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "print(f'{datetime.datetime.now()} - Preparing train_dataloader...')\n",
    "train_data = triplet_CQT(out_length=400, is_label=True, mode=(datatype, train_scale), cut=train_cut, is_random=True)\n",
    "train_dataloader = DataLoader(train_data, BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "print(f'{datetime.datetime.now()} - Preparing test_dataloader...')\n",
    "test_data = CQT(mode=(test_source, datatype, test_scale), out_length=400)\n",
    "test_dataloader = DataLoader(test_data, 1, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "223e0e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1, 72, 400])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for a,p,n,la,lp,ln in train_dataloader:\n",
    "    break\n",
    "\n",
    "a, p, n = a.cuda(device=device_ids[0]), p.cuda(device=device_ids[0]), n.cuda(device=device_ids[0])\n",
    "\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5613690b",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "for i in range(a.shape[0]):\n",
    "    plt.imshow(a[i,0].cpu(), origin='lower')\n",
    "    plt.show()\n",
    "\n",
    "for a, la in test_dataloader:\n",
    "    plt.imshow(a[0,0].cpu(), origin='lower')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "932d0ca1",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5084],\n",
      "        [0.5027],\n",
      "        [0.5035],\n",
      "        [0.5018],\n",
      "        [0.5035],\n",
      "        [0.5011],\n",
      "        [0.4888],\n",
      "        [0.4971],\n",
      "        [0.4955],\n",
      "        [0.4893],\n",
      "        [0.4941],\n",
      "        [0.4965]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6832, device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.module.model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(a,p,n).squeeze(0)\n",
    "    print(out)\n",
    "\n",
    "B, _, _, _ = a.shape\n",
    "target = torch.cat((torch.ones(B), torch.zeros(B))).cuda()\n",
    "\n",
    "loss_fn(out.squeeze(1), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8bea36a",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_quick(softdtw, dataloader):\n",
    "    softdtw.eval()\n",
    "    softdtw.module.model.eval()\n",
    "    labels = []\n",
    "    temp = []\n",
    "    count = -1\n",
    "    for ii, (data, label) in tqdm(enumerate(dataloader)):\n",
    "        labels.append(label)\n",
    "    labels = torch.cat(labels, dim=0) # labels: 库里每首歌的song_id\n",
    "    N = labels.shape[0]\n",
    "    dis2d = np.zeros((N, N))\n",
    "    for ii, (data, label) in tqdm(enumerate(dataloader)):\n",
    "        data = data.cuda(device=device_ids[0])\n",
    "        count += 1\n",
    "        if count == 0: # for中的第一轮循环\n",
    "            temp.append((data, count)) # temp[0] = (data, 0)\n",
    "        else:\n",
    "            for i in range(len(temp)):\n",
    "                dis = softdtw.module.multi_compute_s(data, temp[i][0]).data.cpu().numpy()\n",
    "                dis2d[temp[i][1]][count], dis2d[count][temp[i][1]] = -dis, -dis\n",
    "            temp.append((data, count))\n",
    "\n",
    "    MAP, top10, rank1 = calc_MAP(dis2d[0:labels.shape[0], 0:labels.shape[0]], labels)\n",
    "    print(f'MAP:\\t{MAP:.4f}\\ttop10:\\t{top10:.4f}\\trank1:\\t{rank1:.4f}')\n",
    "    softdtw.train()\n",
    "    softdtw.module.model.train()\n",
    "    return MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a193e176",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_slow_batch(softdtw, dataloader, batch=50, is_dis=False):\n",
    "    softdtw.eval()\n",
    "    softdtw.module.model.eval()\n",
    "    seqs, labels = [], []\n",
    "    for ii, (data, label) in tqdm(enumerate(dataloader)):\n",
    "        input = data.cuda(device=device_ids[0])\n",
    "        seqs.append(input)\n",
    "        labels.append(label)\n",
    "    seqs = torch.cat(seqs, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    N = labels.shape[0]\n",
    "    if N == 350:\n",
    "        query_l = [i // 100 for i in range(100 * 100, 350 * 100)]\n",
    "        ref_l = [i for i in range(100)] * 250\n",
    "    else:\n",
    "        query_l = [i // N for i in range(N * N)] # [0,...,0,1,...,1,...,N,...,N]\n",
    "        ref_l = [i for i in range(N)] * N # [0,...,N,0,...,N,...,0,...,N]\n",
    "    dis2d = np.zeros((N, N))\n",
    "\n",
    "    N = N * N if N != 350 else 100 * 250 # N = N*N\n",
    "    for st in tqdm(range(0, N, batch)):\n",
    "        fi = (st + batch) if st + batch <= N else N\n",
    "        query = seqs[query_l[st: fi], :, :]\n",
    "        ref = seqs[ref_l[st: fi], :, :]\n",
    "        s = softdtw.module.multi_compute_s(query, ref).data.cpu().numpy()\n",
    "        for k in range(st, fi):\n",
    "            i, j = query_l[k], ref_l[k]\n",
    "            if is_dis:\n",
    "                dis2d[i, j] = s[k - st]\n",
    "            else:\n",
    "                dis2d[i, j] = -s[k - st]\n",
    "#     print(labels)\n",
    "#     print(dis2d)\n",
    "    if len(labels) == 350:\n",
    "        MAP, top10, rank1 = calc_MAP(dis2d, labels, [100, 350])\n",
    "    else:\n",
    "        MAP, top10, rank1 = calc_MAP(dis2d, labels)\n",
    "    print(f'MAP:\\t{MAP:.4f}\\ttop10:\\t{top10:.4f}\\trank1:\\t{rank1:.4f}')\n",
    "\n",
    "    softdtw.train()\n",
    "    softdtw.module.model.train()\n",
    "    return MAP, dis2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0185d599",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 545.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:\t1.0000\ttop10:\t0.2000\trank1:\t1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8116b67d90>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAP, dis2d = val_slow_batch(model, test_dataloader)\n",
    "\n",
    "plt.imshow(dis2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e11e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个epoch的训练/测试\n",
    "def train(dataloader, model, loss_fn, optimizer, scheduler):\n",
    "    model.train()\n",
    "    model.module.model.train()\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    batch_num = math.ceil(size/dataloader.batch_size)\n",
    "    \n",
    "    loss_total = 0\n",
    "    num = 0\n",
    "    \n",
    "    for batch, (a, p, n, la, lp, ln) in tqdm(enumerate(dataloader)):\n",
    "        B, _, _, _ = a.shape\n",
    "        target = torch.cat((torch.ones(B), torch.zeros(B))).cuda()\n",
    "        a, p, n = a.cuda(device=device_ids[0]), p.cuda(device=device_ids[0]), n.cuda(device=device_ids[0])\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(a, p, n)\n",
    "        pred = pred.squeeze(1)\n",
    "#         print(pred, target)\n",
    "        loss = loss_fn(pred, target)\n",
    "        loss = loss.sum()\n",
    "#         print(loss)\n",
    "        loss.backward()\n",
    "#         print(list(model.named_parameters())[24][1][0,0,0])\n",
    "#         print(list(model.named_parameters())[24][1].grad[0,0,0])\n",
    "        \n",
    "        optimizer.step()\n",
    "#         print(list(model.named_parameters())[24][1][0,0,0])\n",
    "        loss_total += loss.item()\n",
    "        num += B\n",
    "\n",
    "        if (batch+1) % 100 == 0:\n",
    "            print(f\"Avg loss: {loss.item():.4f}  [{num:>5d}/{size:>5d}]\")\n",
    "            scheduler.step(loss.item())\n",
    "\n",
    "    return loss_total/batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## best_MAP = val_slow_batch(model, test_dataloader)\n",
    "best_MAP = 0\n",
    "\n",
    "# try:\n",
    "#     print(list(model.named_parameters())[24][1].grad[0,0,0])\n",
    "# except:\n",
    "#     pass\n",
    "# print(list(model.named_parameters())[24][1][0,0,0])\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------{datetime.datetime.now()}\")\n",
    "    train_loss = train(train_dataloader, model, loss_fn, optimizer, scheduler)\n",
    "    print(f'train_loss:{train_loss:.6f}')\n",
    "\n",
    "    MAP = 0\n",
    "    print('gdoras_test:')\n",
    "    MAP += val_slow_batch(model, test_dataloader)\n",
    "    if MAP > best_MAP:\n",
    "        print('*****************BEST*****************')\n",
    "        print(f'[epoch {t+1}] {best_MAP:.4f} --- {MAP:.4f}. Save.')\n",
    "        best_MAP = MAP\n",
    "#         torch.save(model.state_dict(), os.path.join(save_dir, f'model_best.pth'))\n",
    "    \n",
    "    if optimizer.state_dict()['param_groups'][0]['lr']<=0:\n",
    "        print(f'Early stop after {t+1} epochs.')\n",
    "        break\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e72f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33945848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 有问题！！！\n",
    "@torch.no_grad()\n",
    "def test(dataloader, model, loss_fn):\n",
    "    # only see loss\n",
    "    model.eval()\n",
    "    model.module.model.eval()\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    batch_num = math.ceil(size/dataloader.batch_size)\n",
    "    loss_total = 0\n",
    "    \n",
    "    for batch, (a, p, n, la, lp, ln) in tqdm(enumerate(dataloader)):\n",
    "            B, _, _, _ = a.shape\n",
    "            target = torch.cat((torch.ones(B), torch.zeros(B))).cuda()\n",
    "            a, p, n = a.cuda(device=device_ids[0]), p.cuda(device=device_ids[0]), n.cuda(device=device_ids[0])\n",
    "            pred = model(a, p, n)\n",
    "            pred = pred.squeeze(1)\n",
    "            loss = loss_fn(pred, target)\n",
    "            loss = loss.sum()\n",
    "            loss.backward()\n",
    "            loss_total += loss.item()\n",
    "            \n",
    "    return loss_total/batch_num"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
