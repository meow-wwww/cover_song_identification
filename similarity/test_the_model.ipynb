{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "557c840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import argparse, os, math\n",
    "import numpy as np\n",
    "from hpcp_loader_for_softdtw import *\n",
    "import models.BaseSPPNet as models\n",
    "from config import DefaultConfig, opt\n",
    "from utility import *\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import resource\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3da1acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6ba5f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = None\n",
    "saved_model_path = './experiment/0.5.1/model_best.pth'\n",
    "lr = 1e-6\n",
    "weight_decay = 0\n",
    "num_workers = 0\n",
    "epochs = 100\n",
    "epochs_finished = 0\n",
    "BATCH_SIZE = 10\n",
    "device_ids = [0]\n",
    "datatype = 'multif0_avg5'\n",
    "train_scale = 'so_short'\n",
    "test_scale = 'so_short'\n",
    "test_source = 'gdoras_train'\n",
    "train_cut = 'front'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fa9e71d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from ./experiment/0.5.1/model_best.pth...\n"
     ]
    }
   ],
   "source": [
    "model = models.NeuralDTW_CNN_Mask_dilation_SPP6(None)\n",
    "model = model.cuda()\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "if saved_model_path != None:\n",
    "    print(f'loading model from {saved_model_path}...')\n",
    "    model.load_state_dict(torch.load(saved_model_path))\n",
    "\n",
    "loss_fn = nn.BCELoss() # loss_fn返回的值已经对每个样本做平均了\n",
    "loss_fn = loss_fn.cuda()\n",
    "loss_fn = nn.DataParallel(loss_fn)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=10,\n",
    "                                                               verbose=True, min_lr=5e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13bd8f1",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Xavier init\n",
    "from torch.nn import init\n",
    "#define the initial function to init the layer's parameters for the network\n",
    "\n",
    "def initNetParams(net):\n",
    "    '''Init net parameters.'''\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_uniform(m.weight)\n",
    "            if m.bias != None:\n",
    "                init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant(m.weight, 1)\n",
    "            init.constant(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.normal(m.weight, std=1e-3)\n",
    "            if m.bias != None:\n",
    "                init.constant(m.bias, 0)\n",
    "\n",
    "initNetParams(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2cee1bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-12 19:27:56.741738 - Preparing train_dataloader...\n",
      "2021-10-12 19:27:56.743375 - Preparing test_dataloader...\n"
     ]
    }
   ],
   "source": [
    "# Dataloader\n",
    "print(f'{datetime.datetime.now()} - Preparing train_dataloader...')\n",
    "train_data = triplet_CQT(out_length=400, is_label=True, mode=(datatype, train_scale), cut=train_cut, is_random=True)\n",
    "train_dataloader = DataLoader(train_data, BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "print(f'{datetime.datetime.now()} - Preparing test_dataloader...')\n",
    "test_data = CQT(mode=(test_source, datatype, test_scale), out_length=400)\n",
    "test_dataloader = DataLoader(test_data, 1, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d0efc0",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "for i in range(a.shape[0]):\n",
    "    plt.imshow(a[i,0].cpu(), origin='lower')\n",
    "    plt.show()\n",
    "\n",
    "for a, la in test_dataloader:\n",
    "    plt.imshow(a[0,0].cpu(), origin='lower')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c6bbc085",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6465],\n",
      "        [0.6506],\n",
      "        [0.5313],\n",
      "        [0.4604],\n",
      "        [0.4884],\n",
      "        [0.5040],\n",
      "        [0.5898],\n",
      "        [0.5896],\n",
      "        [0.5154],\n",
      "        [0.3741],\n",
      "        [0.4077],\n",
      "        [0.4770]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6519, device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for a,p,n,la,lp,ln in train_dataloader:\n",
    "    break\n",
    "\n",
    "a, p, n = a.cuda(device=device_ids[0]), p.cuda(device=device_ids[0]), n.cuda(device=device_ids[0])\n",
    "\n",
    "a.shape\n",
    "\n",
    "model.eval()\n",
    "model.module.model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(a,p,n).squeeze(0)\n",
    "    print(out)\n",
    "\n",
    "B, _, _, _ = a.shape\n",
    "target = torch.cat((torch.ones(B), torch.zeros(B))).cuda()\n",
    "\n",
    "loss_fn(out.squeeze(1), target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20dee6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7846e2c6",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_quick(softdtw, dataloader):\n",
    "    softdtw.eval()\n",
    "    softdtw.module.model.eval()\n",
    "    labels = []\n",
    "    temp = []\n",
    "    count = -1\n",
    "    for ii, (data, label) in tqdm(enumerate(dataloader)):\n",
    "        labels.append(label)\n",
    "    labels = torch.cat(labels, dim=0) # labels: 库里每首歌的song_id\n",
    "    N = labels.shape[0]\n",
    "    dis2d = np.zeros((N, N))\n",
    "    for ii, (data, label) in tqdm(enumerate(dataloader)):\n",
    "        data = data.cuda(device=device_ids[0])\n",
    "        count += 1\n",
    "        if count == 0: # for中的第一轮循环\n",
    "            temp.append((data, count)) # temp[0] = (data, 0)\n",
    "        else:\n",
    "            for i in range(len(temp)):\n",
    "                dis = softdtw.module.multi_compute_s(data, temp[i][0]).data.cpu().numpy()\n",
    "                dis2d[temp[i][1]][count], dis2d[count][temp[i][1]] = -dis, -dis\n",
    "            temp.append((data, count))\n",
    "\n",
    "    MAP, top10, rank1 = calc_MAP(dis2d[0:labels.shape[0], 0:labels.shape[0]], labels)\n",
    "    print(f'MAP:\\t{MAP:.4f}\\ttop10:\\t{top10:.4f}\\trank1:\\t{rank1:.4f}')\n",
    "    softdtw.train()\n",
    "    softdtw.module.model.train()\n",
    "    return MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "62af5337",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def val_slow_batch(softdtw, dataloader, batch=50, is_dis=False):\n",
    "    softdtw.eval()\n",
    "    softdtw.module.model.eval()\n",
    "    seqs, labels = [], []\n",
    "    for ii, (data, label) in tqdm(enumerate(dataloader)):\n",
    "        input = data.cuda(device=device_ids[0])\n",
    "        seqs.append(input)\n",
    "        labels.append(label)\n",
    "    seqs = torch.cat(seqs, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    N = labels.shape[0]\n",
    "    if N == 350:\n",
    "        query_l = [i // 100 for i in range(100 * 100, 350 * 100)]\n",
    "        ref_l = [i for i in range(100)] * 250\n",
    "    else:\n",
    "        query_l = [i // N for i in range(N * N)] # [0,...,0,1,...,1,...,N,...,N]\n",
    "        ref_l = [i for i in range(N)] * N # [0,...,N,0,...,N,...,0,...,N]\n",
    "    dis2d = np.zeros((N, N))\n",
    "\n",
    "    N = N * N if N != 350 else 100 * 250 # N = N*N\n",
    "    for st in tqdm(range(0, N, batch)):\n",
    "        fi = (st + batch) if st + batch <= N else N\n",
    "        query = seqs[query_l[st: fi], :, :]\n",
    "        ref = seqs[ref_l[st: fi], :, :]\n",
    "        s = softdtw.module.multi_compute_s(query, ref).data.cpu().numpy()\n",
    "        for k in range(st, fi):\n",
    "            i, j = query_l[k], ref_l[k]\n",
    "            if is_dis:\n",
    "                dis2d[i, j] = s[k - st]\n",
    "            else:\n",
    "                dis2d[i, j] = -s[k - st]\n",
    "#     print(labels)\n",
    "#     print(dis2d)\n",
    "    if len(labels) == 350:\n",
    "        MAP, top10, rank1 = calc_MAP(dis2d, labels, [100, 350])\n",
    "    else:\n",
    "        MAP, top10, rank1 = calc_MAP(dis2d, labels)\n",
    "    print(f'MAP:\\t{MAP:.4f}\\ttop10:\\t{top10:.4f}\\trank1:\\t{rank1:.4f}')\n",
    "\n",
    "    softdtw.train()\n",
    "    softdtw.module.model.train()\n",
    "    return MAP, dis2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6d9e702d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:00, 546.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP:\t0.9444\ttop10:\t0.2000\trank1:\t1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f47065aeb80>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAP, dis2d = val_slow_batch(model, test_dataloader)\n",
    "\n",
    "plt.imshow(dis2d, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441f5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个epoch的训练/测试\n",
    "def train(dataloader, model, loss_fn, optimizer, scheduler):\n",
    "    model.train()\n",
    "    model.module.model.train()\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    batch_num = math.ceil(size/dataloader.batch_size)\n",
    "    \n",
    "    loss_total = 0\n",
    "    num = 0\n",
    "    \n",
    "    for batch, (a, p, n, la, lp, ln) in tqdm(enumerate(dataloader)):\n",
    "        B, _, _, _ = a.shape\n",
    "        target = torch.cat((torch.ones(B), torch.zeros(B))).cuda()\n",
    "        a, p, n = a.cuda(device=device_ids[0]), p.cuda(device=device_ids[0]), n.cuda(device=device_ids[0])\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(a, p, n)\n",
    "        pred = pred.squeeze(1)\n",
    "#         print(pred, target)\n",
    "        loss = loss_fn(pred, target)\n",
    "        loss = loss.sum()\n",
    "#         print(loss)\n",
    "        loss.backward()\n",
    "#         print(list(model.named_parameters())[24][1][0,0,0])\n",
    "#         print(list(model.named_parameters())[24][1].grad[0,0,0])\n",
    "        \n",
    "        optimizer.step()\n",
    "#         print(list(model.named_parameters())[24][1][0,0,0])\n",
    "        loss_total += loss.item()\n",
    "        num += B\n",
    "\n",
    "        if (batch+1) % 100 == 0:\n",
    "            print(f\"Avg loss: {loss.item():.4f}  [{num:>5d}/{size:>5d}]\")\n",
    "            scheduler.step(loss.item())\n",
    "\n",
    "    return loss_total/batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a9a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## best_MAP = val_slow_batch(model, test_dataloader)\n",
    "best_MAP = 0\n",
    "\n",
    "# try:\n",
    "#     print(list(model.named_parameters())[24][1].grad[0,0,0])\n",
    "# except:\n",
    "#     pass\n",
    "# print(list(model.named_parameters())[24][1][0,0,0])\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------{datetime.datetime.now()}\")\n",
    "    train_loss = train(train_dataloader, model, loss_fn, optimizer, scheduler)\n",
    "    print(f'train_loss:{train_loss:.6f}')\n",
    "\n",
    "    MAP = 0\n",
    "    print('gdoras_test:')\n",
    "    MAP += val_slow_batch(model, test_dataloader)\n",
    "    if MAP > best_MAP:\n",
    "        print('*****************BEST*****************')\n",
    "        print(f'[epoch {t+1}] {best_MAP:.4f} --- {MAP:.4f}. Save.')\n",
    "        best_MAP = MAP\n",
    "#         torch.save(model.state_dict(), os.path.join(save_dir, f'model_best.pth'))\n",
    "    \n",
    "    if optimizer.state_dict()['param_groups'][0]['lr']<=0:\n",
    "        print(f'Early stop after {t+1} epochs.')\n",
    "        break\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e3f63f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3d5e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924707c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 有问题！！！\n",
    "@torch.no_grad()\n",
    "def test(dataloader, model, loss_fn):\n",
    "    # only see loss\n",
    "    model.eval()\n",
    "    model.module.model.eval()\n",
    "    \n",
    "    size = len(dataloader.dataset)\n",
    "    batch_num = math.ceil(size/dataloader.batch_size)\n",
    "    loss_total = 0\n",
    "    \n",
    "    for batch, (a, p, n, la, lp, ln) in tqdm(enumerate(dataloader)):\n",
    "            B, _, _, _ = a.shape\n",
    "            target = torch.cat((torch.ones(B), torch.zeros(B))).cuda()\n",
    "            a, p, n = a.cuda(device=device_ids[0]), p.cuda(device=device_ids[0]), n.cuda(device=device_ids[0])\n",
    "            pred = model(a, p, n)\n",
    "            pred = pred.squeeze(1)\n",
    "            loss = loss_fn(pred, target)\n",
    "            loss = loss.sum()\n",
    "            loss.backward()\n",
    "            loss_total += loss.item()\n",
    "            \n",
    "    return loss_total/batch_num"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
