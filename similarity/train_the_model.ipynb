{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "refined-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import random\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import argparse, os, math\n",
    "import numpy as np\n",
    "from hpcp_loader_for_softdtw import *\n",
    "import models.BaseSPPNet as models\n",
    "from config import DefaultConfig, opt\n",
    "from utility import *\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import resource\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-cathedral",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# argparse\n",
    "save_dir = None\n",
    "lr = 1e-4\n",
    "saved_model_path = None\n",
    "epochs = 0\n",
    "epochs_finished = 0\n",
    "num_floor = -1\n",
    "BATCH_SIZE = 16\n",
    "overlap = 4\n",
    "threshold = 0.05\n",
    "\n",
    "print('--------------ArgParse--------------')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-d', '--save_dir', help='目标存储目录')\n",
    "parser.add_argument('-s', '--saved_model', help='以训练过的模型')\n",
    "parser.add_argument('--lr', type=float, help='学习率')\n",
    "parser.add_argument('-e', '--epochs', type=int, help='有几个epoch')\n",
    "# parser.add_argument('--epochs_finished', type=int, help='已经完成了几个epoch')\n",
    "parser.add_argument('-f', '--out_floor', type=int, help='输出在第几层(0，1，2，3)')\n",
    "parser.add_argument('-g', '--gpu', help='要用的gpu号')\n",
    "parser.add_argument('-b', '--batch_size', type=int, help='batch_size')\n",
    "parser.add_argument('-o', '--overlap', type=int, help='切出训练数据时，跳步占全部长度的几分之一')\n",
    "parser.add_argument('-t','--threshold', type=float, help='生成结果用的阈值')\n",
    "# parser.add_argument('--loss', type=int, help='损失函数')\n",
    "parser.add_argument('--vt', help='验证/测试集')\n",
    "parser.add_argument('--label', help='label的类型')\n",
    "parser.add_argument('--fold', help='fold的类型')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "assert args.save_dir != None, ('请输入存储目录')\n",
    "if not os.path.exists(args.save_dir):\n",
    "    print(f'Save_dir {args.save_dir} does not exist. Will create one.')\n",
    "    save_dir = args.save_dir\n",
    "    os.mkdir(save_dir)\n",
    "else:\n",
    "    print(f'Save_dir {args.save_dir} already exist. Will save to this directory.')\n",
    "    save_dir = args.save_dir\n",
    "\n",
    "\n",
    "if args.saved_model == None:\n",
    "    print('Don\\'t use saved model, train from scratch')\n",
    "else:\n",
    "    print(f'Use saved model[{args.saved_model}], train from it')\n",
    "saved_model_path = args.saved_model\n",
    "\n",
    "if args.lr == None:\n",
    "    print('Using default lr=1e-4')\n",
    "else:\n",
    "    lr = args.lr\n",
    "    print(f'Using lr from command: {lr}')\n",
    "\n",
    "assert args.epochs != None, ('请输入epochs数')\n",
    "epochs = args.epochs\n",
    "\n",
    "assert args.out_floor != None, ('请输入输出的层数')\n",
    "assert args.out_floor in [0,1,2,3], ('输入的层数必须为0 1 2 3之一')\n",
    "num_floor = args.out_floor\n",
    "\n",
    "assert args.gpu != None, ('请输入要用的gpu号')\n",
    "device_ids = list(map(lambda x: int(x), args.gpu.split(',')))\n",
    "print(f'using device_ids: {device_ids}')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "print(f'device count: {torch.cuda.device_count()}')\n",
    "print(f'current device: {torch.cuda.current_device()}')\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "if args.batch_size == None:\n",
    "    print(f'using default batch_size {BATCH_SIZE}')\n",
    "else:\n",
    "    BATCH_SIZE = args.batch_size\n",
    "    print(f'using batch_size from command: {BATCH_SIZE}')\n",
    "    \n",
    "if args.overlap == None:\n",
    "    print(f'using default overlap {overlap}')\n",
    "else:\n",
    "    overlap = args.overlap\n",
    "    print(f'using overlap from command: {overlap}')\n",
    "overlap = 258//overlap\n",
    "\n",
    "if args.threshold == None:\n",
    "    print(f'using default threshold {threshold}')\n",
    "else:\n",
    "    threshold = args.threshold\n",
    "    print(f'using threshold from command: {threshold}')\n",
    "    \n",
    "# if args.loss == 0:\n",
    "#     loss_fn = loss_function.CrossEntropyLoss_Origin()\n",
    "# elif args.loss == 1:\n",
    "#     loss_fn = loss_function.CrossEntropyLoss_for_FA_CE()\n",
    "# elif args.loss == 2:\n",
    "#     loss_fn = loss_function.CrossEntropyLoss_for_FA_CE_VNV()\n",
    "# elif args.loss == 3:\n",
    "#     loss_fn = loss_function.CrossEntropyLoss_for_FA_CE_TF()\n",
    "# elif args.loss == 4:\n",
    "#     loss_fn = loss_function.CrossEntropyLoss_for_FA_CESQ_TF()\n",
    "# else:\n",
    "#     assert False, ('损失函数代号不在范围内')\n",
    "loss_fn = nn.BCELoss()\n",
    "print(f'Using loss_function: {loss_fn.__class__.__name__}')\n",
    "\n",
    "assert args.vt[0]!=args.vt[1], ('验证集、测试集不能一样')\n",
    "assert args.vt[0] in '0123456789', ('验证集index out of range')\n",
    "assert args.vt[1] in '0123456789', ('测试集index out of range')\n",
    "valid_fold_index_list = [int(args.vt[0])]\n",
    "test_fold_index_list = [int(args.vt[1])]\n",
    "train_fold_index_list = [i for i in range(10) if (i not in valid_fold_index_list and i not in test_fold_index_list)]\n",
    "print(f'\\ttrain: {train_fold_index_list}\\n\\tvalid: {valid_fold_index_list}\\n\\ttest: {test_fold_index_list}')\n",
    "\n",
    "assert args.label in ['origin', 'real_one_hot', '3bin', '1bin'], ('label类型不在规定范围内')\n",
    "label_kind = args.label\n",
    "print(f'label kind: {label_kind}')\n",
    "\n",
    "fold_version = args.fold\n",
    "print(f'fold version: {fold_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "double-hayes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------+\n",
      "| user config:\n",
      "| model NeuralDTW_CNN_Mask_dilation_SPP6\n",
      "| feature cqt\n",
      "| load_model_path None\n",
      "| load_latest False\n",
      "| batch_size 10\n",
      "| use_gpu True\n",
      "| num_workers 0\n",
      "| max_epoch 20\n",
      "| lr 0.001\n",
      "| lr_decay 0.8\n",
      "| weight_decay 1e-05\n",
      "| notes mask\n",
      "| debug_file params/debug_file.txt\n",
      "+------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/S3/DAA/wxy/cover_song_identification/similarity/config.py:33: UserWarning: Warning: opt has not attribut is_label\n",
      "  warnings.warn(\"Warning: opt has not attribut %s\" % k)\n",
      "/S3/DAA/wxy/cover_song_identification/similarity/config.py:33: UserWarning: Warning: opt has not attribut is_random\n",
      "  warnings.warn(\"Warning: opt has not attribut %s\" % k)\n",
      "/S3/DAA/wxy/cover_song_identification/similarity/config.py:33: UserWarning: Warning: opt has not attribut save_model\n",
      "  warnings.warn(\"Warning: opt has not attribut %s\" % k)\n",
      "/S3/DAA/wxy/cover_song_identification/similarity/config.py:33: UserWarning: Warning: opt has not attribut manner\n",
      "  warnings.warn(\"Warning: opt has not attribut %s\" % k)\n",
      "/S3/DAA/wxy/cover_song_identification/similarity/config.py:33: UserWarning: Warning: opt has not attribut params\n",
      "  warnings.warn(\"Warning: opt has not attribut %s\" % k)\n",
      "/S3/DAA/wxy/cover_song_identification/similarity/config.py:33: UserWarning: Warning: opt has not attribut test_length\n",
      "  warnings.warn(\"Warning: opt has not attribut %s\" % k)\n",
      "/S3/DAA/wxy/cover_song_identification/similarity/config.py:33: UserWarning: Warning: opt has not attribut zo\n",
      "  warnings.warn(\"Warning: opt has not attribut %s\" % k)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3,4,5'\n",
    "device_ids = [0,1]\n",
    "\n",
    "kwargs = {'model': 'NeuralDTW_CNN_Mask_dilation_SPP6', 'num_workers': 0, 'batch_size': 10, 'is_label': True,\n",
    "              'is_random': False, 'notes': 'mask', 'save_model': True, 'manner': 'train',\n",
    "              'params': 'params/neuraldtw/mask0', 'test_length': 400, 'zo': False }\n",
    "\n",
    "opt.feature = 'cqt'\n",
    "opt.notes = 'SoftDTW'\n",
    "opt.model = 'SoftDTW'\n",
    "opt.batch_size = 'batch_size'\n",
    "opt._parse(kwargs) # opt.model = 'NeuralDTW_CNN_Mask_dilation_SPP6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conditional-disabled",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw model\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = None\n",
    "\n",
    "model = getattr(models, opt.model)(None)\n",
    "model = model.cuda()\n",
    "model = nn.DataParallel(model)\n",
    "# model = model.to(device)\n",
    "\n",
    "if saved_model_path != None:\n",
    "    print(f'loading model from {saved_model_path}...')\n",
    "    #model = torch.load(saved_model_path)\n",
    "    model.load_state_dict(torch.load(saved_model_path))\n",
    "else:\n",
    "    print('raw model')\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "loss_fn = loss_fn.cuda()\n",
    "loss_fn = nn.DataParallel(loss_fn)\n",
    "# loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "suspended-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)# , weight_decay=opt.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=10,\n",
    "                                                               verbose=True, min_lr=5e-10)# 5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "alone-alcohol",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-20 17:15:25.102465 - Preparing train_dataloader...\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "print(f'{datetime.datetime.now()} - Preparing train_dataloader...')\n",
    "train_data = triplet_CQT(out_length=400, is_label=kwargs['is_label'], is_random=kwargs['is_random'])\n",
    "train_dataloader = DataLoader(train_data, opt.batch_size, shuffle=True, num_workers=opt.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "imposed-holly",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 多个epoch的训练+测试\n",
    "def train(max_epoch):\n",
    "    model.train()\n",
    "    model.module.model.train()\n",
    "    best_MAP = 0\n",
    "    for epoch in range(max_epoch):\n",
    "        print(f'---------epoch {epoch}----------')\n",
    "        running_loss = 0\n",
    "        num = 0\n",
    "        for ii, (a, p, n, la, lp, ln) in tqdm(enumerate(train_dataloader)):\n",
    "            B, _, _, _ = a.shape\n",
    "            target = torch.cat((torch.ones(B), torch.zeros(B))).cuda()\n",
    "            # train model\n",
    "            # a = a.requires_grad_().to(opt.device)\n",
    "            # p = p.requires_grad_().to(opt.device)\n",
    "            # n = n.requires_grad_().to(opt.device)\n",
    "            a, p, n = a.cuda(device=device_ids[0]), p.cuda(device=device_ids[0]), n.cuda(device=device_ids[0])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(a, p, n)\n",
    "            pred = pred.squeeze(1)\n",
    "            loss = loss_fn(pred, target)\n",
    "            print(loss)\n",
    "            loss = loss.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            num += B\n",
    "\n",
    "            if (ii+1) % 4 == 0 :\n",
    "                print(num)\n",
    "                running_loss /= num\n",
    "                print(\"train_loss:\", running_loss)\n",
    "\n",
    "#                     MAP = 0\n",
    "#                     print(\"Youtube350:\")\n",
    "#                     MAP += val_slow_batch(model, val_dataloader, batch=100, is_dis=kwargs['zo'])\n",
    "#                     print(\"CoverSong80:\")\n",
    "#                     MAP += val_slow_batch(model, val_dataloader80, batch=100, is_dis=kwargs['zo'])\n",
    "                # print(\"Youtube350:\")\n",
    "                # MAP += val_quick(model, val_dataloader)\n",
    "                # print(\"CoverSong80:\")\n",
    "                # MAP += val_quick(model, val_dataloader80)\n",
    "                # print(\"Marukars:\")\n",
    "                # MAP += val_slow_batch(model, val_dataloader_marukars, batch=100, is_dis=kwargs['zo'])\n",
    "#                     if MAP > best_MAP:\n",
    "#                         best_MAP = MAP\n",
    "#                         print('*****************BEST*****************')\n",
    "#                     if kwargs['save_model'] == True:\n",
    "#                         if parallel:\n",
    "#                             model.module.save(opt.notes)\n",
    "#                         else:\n",
    "#                             model.save(opt.notes)\n",
    "                scheduler.step(running_loss)\n",
    "                running_loss = 0\n",
    "                num = 0\n",
    "\n",
    "            \n",
    "#         if loss.item() != loss.item():\n",
    "#             print('Train NaN!')\n",
    "#             print(loss_gpus)\n",
    "#             print('====================================================')\n",
    "#             torch.save((X,y), os.path.join(save_dir, 'Xy_nan.pt'))\n",
    "#             torch.save(model.state_dict(), os.path.join(save_dir, 'model_nan.pth'))\n",
    "#             exit()\n",
    "\n",
    "            \n",
    "#     scheduler.step()\n",
    "#     return loss_total/batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "correct-currency",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, out_floor):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        size = len(dataloader.dataset)\n",
    "        batch_num = math.ceil(size/dataloader.batch_size)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_loss_v, test_loss_nv = 0, 0\n",
    "        test_loss_f, test_loss_t = 0, 0\n",
    "        oa_avg, vr_avg, vfa_avg, rpa_avg, rca_avg = 0, 0, 0, 0, 0\n",
    "    \n",
    "    \n",
    "        for X, y in dataloader:\n",
    "            # X, y = X.to(device), y.to(device)\n",
    "            X, y = X.cuda(device=device_ids[0]), y.cuda(device=device_ids[0])\n",
    "            Xpred = model(X, out_floor)\n",
    "            Xout = utils.salience_to_output(Xpred.clone().detach(), threshold=threshold)\n",
    "            \n",
    "            if out_floor == 0:\n",
    "                loss = loss_fn(Xpred, y, threshold)\n",
    "                oa, vr, vfa, rpa, rca = evaluate.evaluate(Xout, y, out_floor)\n",
    "            else:\n",
    "                y_downsample = utils.downsample(y, out_floor)\n",
    "                loss = loss_fn(Xpred, y_downsample, threshold)\n",
    "                oa, vr, vfa, rpa, rca = evaluate.evaluate(Xout, y_downsample, out_floor)\n",
    "                \n",
    "            if args.loss == 2:\n",
    "                loss_gather = (loss[0].sum()+loss[2].sum())/(loss[1].sum()+loss[3].sum())\n",
    "                loss_v_gather = loss[0].sum()/loss[1].sum() if loss[1].sum() else loss[1].sum()*0\n",
    "                loss_nv_gather = loss[2].sum()/loss[3].sum() if loss[3].sum() else loss[3].sum()*0\n",
    "                test_loss_v += loss_v_gather.item()\n",
    "                test_loss_nv += loss_nv_gather.item()\n",
    "            elif args.loss in [3,4]:\n",
    "                loss_gather = (loss[0].sum()+loss[2].sum())/(loss[1].sum()+loss[3].sum())\n",
    "                loss_f_gather = loss[0].sum()/loss[1].sum() if loss[1].sum() else loss[1].sum()*0\n",
    "                loss_t_gather = loss[2].sum()/loss[3].sum() if loss[3].sum() else loss[3].sum()*0\n",
    "                test_loss_f += loss_f_gather.item()\n",
    "                test_loss_t += loss_t_gather.item()\n",
    "            elif args.loss in [0,1]:\n",
    "                loss_gather = loss.sum()\n",
    "                \n",
    "            if loss_gather.item() != loss_gather.item():\n",
    "                print('Test NaN!')\n",
    "                print(loss)\n",
    "                print('====================================================')\n",
    "                torch.save((X,y), os.path.join(save_dir, 'Xy_nan.pt'))\n",
    "                torch.save(model.state_dict(), os.path.join(save_dir, 'model_nan.pth'))\n",
    "                exit()\n",
    "            \n",
    "            test_loss += loss_gather.item()\n",
    "            \n",
    "    \n",
    "    print(f\"Test Error: Avg loss: {test_loss:.4f} \\n\")\n",
    "    print(f\"Test OA\\t{oa_avg:.4f}\\tVR\\t{vr_avg:.4f}\\tVFA\\t{vfa_avg:.4f}\\tRPA\\t{rpa_avg:.4f}\\tRCA\\t{rca_avg:.4f}\\n\")\n",
    "    \n",
    "    if args.loss in [0,1,2]:\n",
    "        return (test_loss, test_loss_v, test_loss_nv), oa_avg, vr_avg, vfa_avg, rpa_avg, rca_avg\n",
    "    elif args.loss in [3,4]:\n",
    "        return (test_loss, test_loss_f, test_loss_t), oa_avg, vr_avg, vfa_avg, rpa_avg, rca_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "light-neighbor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------epoch 0----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/yangds/anaconda3/envs/csi2/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/yangds/anaconda3/envs/csi2/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11.8115,  6.9740,  0.5494], device='cuda:0', grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:10, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0079, 6.3098, 4.7275], device='cuda:0', grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:12,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8137, 1.7301, 8.7336], device='cuda:0', grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:14,  4.71s/it]\n"
     ]
    }
   ],
   "source": [
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,p,n,la,lp,ln in train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, p, n = a.cuda(device=device_ids[0]), p.cuda(device=device_ids[0]), n.cuda(device=device_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.module.model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(a,p,n).squeeze(0)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-jewelry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-appliance",
   "metadata": {
    "code_folding": [
     18,
     22,
     30,
     43,
     50,
     61
    ]
   },
   "outputs": [],
   "source": [
    "# # 训练模型🌟\n",
    "# 多个epoch训练，每个epoch后在验证集上测试\n",
    "\n",
    "best_oa = 0\n",
    "\n",
    "_, oa, _, _, _, _ = test(valid_dataloader, model, loss_fn, num_floor)\n",
    "print(f'验证集原始OA: {oa:.4f}.')\n",
    "best_oa = oa\n",
    "\n",
    "for t in range(epochs_finished, epochs_finished+epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------{datetime.datetime.now()}\")\n",
    "    train_loss = train(train_dataloader, model, loss_fn, optimizer, scheduler_decay, num_floor)\n",
    "    valid_loss, oa, _, _, _, _ = test(valid_dataloader, model, loss_fn, num_floor)\n",
    "    test_loss, test_oa, _, _, _, _ = test(test_dataloader, model, loss_fn, num_floor)\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_oa_list.append(oa)\n",
    "    test_oa_list.append(test_oa)\n",
    "    if args.loss in [0,1]:\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        test_loss_list.append(test_loss)\n",
    "        scheduler_stop.step(valid_loss)\n",
    "    elif args.loss == 2:\n",
    "        valid_loss_list.append(valid_loss[0])\n",
    "        valid_loss_v_list.append(valid_loss[1])\n",
    "        valid_loss_nv_list.append(valid_loss[2])\n",
    "        scheduler_stop.step(valid_loss[0])\n",
    "        test_loss_list.append(test_loss[0])\n",
    "        test_loss_v_list.append(test_loss[1])\n",
    "        test_loss_nv_list.append(test_loss[2])\n",
    "    elif args.loss in [3,4]:\n",
    "        valid_loss_list.append(valid_loss[0])\n",
    "        valid_loss_f_list.append(valid_loss[1])\n",
    "        valid_loss_t_list.append(valid_loss[2])\n",
    "        scheduler_stop.step(valid_loss[0])\n",
    "        test_loss_list.append(test_loss[0])\n",
    "        test_loss_f_list.append(test_loss[1])\n",
    "        test_loss_t_list.append(test_loss[2])\n",
    "    \n",
    "    if optimizer.state_dict()['param_groups'][0]['lr']<=0:\n",
    "        print(f'Early stop after {t+1} epochs.')\n",
    "        break\n",
    "    \n",
    "    if args.loss in [0,1]:\n",
    "        plt.plot(range(1,len(train_loss_list)+1), train_loss_list, 'y')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_list, 'm')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_list, 'r')\n",
    "        plt.plot(range(1, len(valid_oa_list)+1), valid_oa_list, 'b')\n",
    "        plt.plot(range(1, len(test_oa_list)+1), test_oa_list, 'b--')\n",
    "        plt.legend(['train loss', 'valid loss', 'test_loss','valid acc','test acc'])\n",
    "    elif args.loss == 2:\n",
    "        plt.plot(range(1,len(train_loss_list)+1), train_loss_list, 'y')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_list, 'm')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_v_list, 'm--')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_nv_list, 'm-.')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_list, 'r')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_v_list, 'r--')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_nv_list, 'r-.')\n",
    "        plt.plot(range(1, len(valid_oa_list)+1), valid_oa_list, 'b')\n",
    "        plt.plot(range(1, len(test_oa_list)+1), test_oa_list, 'b--')\n",
    "        plt.legend(['train loss', 'valid loss', 'valid loss(V)', 'valid loss(NV)', 'test loss', 'test loss(V)', 'test loss(NV)','valid acc','test acc'])\n",
    "    elif args.loss in [3,4]:\n",
    "        plt.plot(range(1,len(train_loss_list)+1), train_loss_list, 'y')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_list, 'm')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_f_list, 'm--')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_t_list, 'm-.')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_list, 'r')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_f_list, 'r--')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_t_list, 'r-.')\n",
    "        plt.plot(range(1, len(valid_oa_list)+1), valid_oa_list, 'b')\n",
    "        plt.plot(range(1, len(test_oa_list)+1), test_oa_list, 'b--')\n",
    "        plt.legend(['train loss', 'valid loss', 'valid loss(F)', 'valid loss(T)', 'test loss', 'test loss(F)', 'test loss(T)','valid acc','test acc'])\n",
    "    \n",
    "    plt.savefig(os.path.join(save_dir, 'loss.png'))\n",
    "    \n",
    "    # 保存最优模型\n",
    "    if oa > best_oa:\n",
    "        with torch.no_grad():\n",
    "            print(f'[in epoch {t+1}, OA got new best: from {best_oa:.4f} to {oa:.4f}. Will save the model]')\n",
    "            best_oa = oa\n",
    "            # torch.save(model, os.path.join(save_dir, f'model_floor{num_floor}_best.pth'))\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, f'model_floor{num_floor}_best.pth'))\n",
    "    \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:csi2]",
   "language": "python",
   "name": "conda-env-csi2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
