{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "refined-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import random\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import argparse, os, math\n",
    "import numpy as np\n",
    "from hpcp_loader_for_softdtw import *\n",
    "import models.BaseSPPNet as models\n",
    "from config import DefaultConfig, opt\n",
    "from utility import *\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import resource\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-cathedral",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# argparse\n",
    "save_dir = None\n",
    "lr = 1e-4\n",
    "saved_model_path = None\n",
    "epochs = 0\n",
    "epochs_finished = 0\n",
    "num_floor = -1\n",
    "BATCH_SIZE = 16\n",
    "overlap = 4\n",
    "threshold = 0.05\n",
    "\n",
    "print('--------------ArgParse--------------')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-d', '--save_dir', help='ÁõÆÊ†áÂ≠òÂÇ®ÁõÆÂΩï')\n",
    "parser.add_argument('-s', '--saved_model', help='‰ª•ËÆ≠ÁªÉËøáÁöÑÊ®°Âûã')\n",
    "parser.add_argument('--lr', type=float, help='Â≠¶‰π†Áéá')\n",
    "parser.add_argument('-e', '--epochs', type=int, help='ÊúâÂá†‰∏™epoch')\n",
    "# parser.add_argument('--epochs_finished', type=int, help='Â∑≤ÁªèÂÆåÊàê‰∫ÜÂá†‰∏™epoch')\n",
    "parser.add_argument('-f', '--out_floor', type=int, help='ËæìÂá∫Âú®Á¨¨Âá†Â±Ç(0Ôºå1Ôºå2Ôºå3)')\n",
    "parser.add_argument('-g', '--gpu', help='Ë¶ÅÁî®ÁöÑgpuÂè∑')\n",
    "parser.add_argument('-b', '--batch_size', type=int, help='batch_size')\n",
    "parser.add_argument('-o', '--overlap', type=int, help='ÂàáÂá∫ËÆ≠ÁªÉÊï∞ÊçÆÊó∂ÔºåË∑≥Ê≠•Âç†ÂÖ®ÈÉ®ÈïøÂ∫¶ÁöÑÂá†ÂàÜ‰πã‰∏Ä')\n",
    "parser.add_argument('-t','--threshold', type=float, help='ÁîüÊàêÁªìÊûúÁî®ÁöÑÈòàÂÄº')\n",
    "# parser.add_argument('--loss', type=int, help='ÊçüÂ§±ÂáΩÊï∞')\n",
    "parser.add_argument('--vt', help='È™åËØÅ/ÊµãËØïÈõÜ')\n",
    "parser.add_argument('--label', help='labelÁöÑÁ±ªÂûã')\n",
    "parser.add_argument('--fold', help='foldÁöÑÁ±ªÂûã')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "assert args.save_dir != None, ('ËØ∑ËæìÂÖ•Â≠òÂÇ®ÁõÆÂΩï')\n",
    "if not os.path.exists(args.save_dir):\n",
    "    print(f'Save_dir {args.save_dir} does not exist. Will create one.')\n",
    "    save_dir = args.save_dir\n",
    "    os.mkdir(save_dir)\n",
    "else:\n",
    "    print(f'Save_dir {args.save_dir} already exist. Will save to this directory.')\n",
    "    save_dir = args.save_dir\n",
    "\n",
    "\n",
    "if args.saved_model == None:\n",
    "    print('Don\\'t use saved model, train from scratch')\n",
    "else:\n",
    "    print(f'Use saved model[{args.saved_model}], train from it')\n",
    "saved_model_path = args.saved_model\n",
    "\n",
    "if args.lr == None:\n",
    "    print('Using default lr=1e-4')\n",
    "else:\n",
    "    lr = args.lr\n",
    "    print(f'Using lr from command: {lr}')\n",
    "\n",
    "assert args.epochs != None, ('ËØ∑ËæìÂÖ•epochsÊï∞')\n",
    "epochs = args.epochs\n",
    "\n",
    "assert args.out_floor != None, ('ËØ∑ËæìÂÖ•ËæìÂá∫ÁöÑÂ±ÇÊï∞')\n",
    "assert args.out_floor in [0,1,2,3], ('ËæìÂÖ•ÁöÑÂ±ÇÊï∞ÂøÖÈ°ª‰∏∫0 1 2 3‰πã‰∏Ä')\n",
    "num_floor = args.out_floor\n",
    "\n",
    "assert args.gpu != None, ('ËØ∑ËæìÂÖ•Ë¶ÅÁî®ÁöÑgpuÂè∑')\n",
    "device_ids = list(map(lambda x: int(x), args.gpu.split(',')))\n",
    "print(f'using device_ids: {device_ids}')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
    "print(f'device count: {torch.cuda.device_count()}')\n",
    "print(f'current device: {torch.cuda.current_device()}')\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "if args.batch_size == None:\n",
    "    print(f'using default batch_size {BATCH_SIZE}')\n",
    "else:\n",
    "    BATCH_SIZE = args.batch_size\n",
    "    print(f'using batch_size from command: {BATCH_SIZE}')\n",
    "    \n",
    "if args.overlap == None:\n",
    "    print(f'using default overlap {overlap}')\n",
    "else:\n",
    "    overlap = args.overlap\n",
    "    print(f'using overlap from command: {overlap}')\n",
    "overlap = 258//overlap\n",
    "\n",
    "if args.threshold == None:\n",
    "    print(f'using default threshold {threshold}')\n",
    "else:\n",
    "    threshold = args.threshold\n",
    "    print(f'using threshold from command: {threshold}')\n",
    "    \n",
    "# if args.loss == 0:\n",
    "#     loss_fn = loss_function.CrossEntropyLoss_Origin()\n",
    "# elif args.loss == 1:\n",
    "#     loss_fn = loss_function.CrossEntropyLoss_for_FA_CE()\n",
    "# elif args.loss == 2:\n",
    "#     loss_fn = loss_function.CrossEntropyLoss_for_FA_CE_VNV()\n",
    "# elif args.loss == 3:\n",
    "#     loss_fn = loss_function.CrossEntropyLoss_for_FA_CE_TF()\n",
    "# elif args.loss == 4:\n",
    "#     loss_fn = loss_function.CrossEntropyLoss_for_FA_CESQ_TF()\n",
    "# else:\n",
    "#     assert False, ('ÊçüÂ§±ÂáΩÊï∞‰ª£Âè∑‰∏çÂú®ËåÉÂõ¥ÂÜÖ')\n",
    "loss_fn = nn.BCELoss()\n",
    "print(f'Using loss_function: {loss_fn.__class__.__name__}')\n",
    "\n",
    "assert args.vt[0]!=args.vt[1], ('È™åËØÅÈõÜ„ÄÅÊµãËØïÈõÜ‰∏çËÉΩ‰∏ÄÊ†∑')\n",
    "assert args.vt[0] in '0123456789', ('È™åËØÅÈõÜindex out of range')\n",
    "assert args.vt[1] in '0123456789', ('ÊµãËØïÈõÜindex out of range')\n",
    "valid_fold_index_list = [int(args.vt[0])]\n",
    "test_fold_index_list = [int(args.vt[1])]\n",
    "train_fold_index_list = [i for i in range(10) if (i not in valid_fold_index_list and i not in test_fold_index_list)]\n",
    "print(f'\\ttrain: {train_fold_index_list}\\n\\tvalid: {valid_fold_index_list}\\n\\ttest: {test_fold_index_list}')\n",
    "\n",
    "assert args.label in ['origin', 'real_one_hot', '3bin', '1bin'], ('labelÁ±ªÂûã‰∏çÂú®ËßÑÂÆöËåÉÂõ¥ÂÜÖ')\n",
    "label_kind = args.label\n",
    "print(f'label kind: {label_kind}')\n",
    "\n",
    "fold_version = args.fold\n",
    "print(f'fold version: {fold_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "double-hayes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------+\n",
      "| user config:\n",
      "| model NeuralDTW_CNN_Mask_dilation_SPP6\n",
      "| feature cqt\n",
      "| load_model_path None\n",
      "| load_latest False\n",
      "| batch_size 10\n",
      "| use_gpu True\n",
      "| num_workers 0\n",
      "| max_epoch 20\n",
      "| lr 0.001\n",
      "| lr_decay 0.8\n",
      "| weight_decay 1e-05\n",
      "| notes mask\n",
      "| debug_file params/debug_file.txt\n",
      "+------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/S3/DAA/wxy/cover_song_identification/similarity/config.py:33: UserWarning: Warning: opt has not attribut is_label\n",
      "  warnings.warn(\"Warning: opt has not attribut %s\" % k)\n",
      "/S3/DAA/wxy/cover_song_identification/similarity/config.py:33: UserWarning: Warning: opt has not attribut is_random\n",
      "  warnings.warn(\"Warning: opt has not attribut %s\" % k)\n",
      "/S3/DAA/wxy/cover_song_identification/similarity/config.py:33: UserWarning: Warning: opt has not attribut save_model\n",
      "  warnings.warn(\"Warning: opt has not attribut %s\" % k)\n",
      "/S3/DAA/wxy/cover_song_identification/similarity/config.py:33: UserWarning: Warning: opt has not attribut manner\n",
      "  warnings.warn(\"Warning: opt has not attribut %s\" % k)\n",
      "/S3/DAA/wxy/cover_song_identification/similarity/config.py:33: UserWarning: Warning: opt has not attribut params\n",
      "  warnings.warn(\"Warning: opt has not attribut %s\" % k)\n",
      "/S3/DAA/wxy/cover_song_identification/similarity/config.py:33: UserWarning: Warning: opt has not attribut test_length\n",
      "  warnings.warn(\"Warning: opt has not attribut %s\" % k)\n",
      "/S3/DAA/wxy/cover_song_identification/similarity/config.py:33: UserWarning: Warning: opt has not attribut zo\n",
      "  warnings.warn(\"Warning: opt has not attribut %s\" % k)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3,4,5'\n",
    "device_ids = [0,1]\n",
    "\n",
    "kwargs = {'model': 'NeuralDTW_CNN_Mask_dilation_SPP6', 'num_workers': 0, 'batch_size': 10, 'is_label': True,\n",
    "              'is_random': False, 'notes': 'mask', 'save_model': True, 'manner': 'train',\n",
    "              'params': 'params/neuraldtw/mask0', 'test_length': 400, 'zo': False }\n",
    "\n",
    "opt.feature = 'cqt'\n",
    "opt.notes = 'SoftDTW'\n",
    "opt.model = 'SoftDTW'\n",
    "opt.batch_size = 'batch_size'\n",
    "opt._parse(kwargs) # opt.model = 'NeuralDTW_CNN_Mask_dilation_SPP6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conditional-disabled",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw model\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = None\n",
    "\n",
    "model = getattr(models, opt.model)(None)\n",
    "model = model.cuda()\n",
    "model = nn.DataParallel(model)\n",
    "# model = model.to(device)\n",
    "\n",
    "if saved_model_path != None:\n",
    "    print(f'loading model from {saved_model_path}...')\n",
    "    #model = torch.load(saved_model_path)\n",
    "    model.load_state_dict(torch.load(saved_model_path))\n",
    "else:\n",
    "    print('raw model')\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "loss_fn = loss_fn.cuda()\n",
    "loss_fn = nn.DataParallel(loss_fn)\n",
    "# loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "suspended-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)# , weight_decay=opt.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=10,\n",
    "                                                               verbose=True, min_lr=5e-10)# 5e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "alone-alcohol",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-20 17:15:25.102465 - Preparing train_dataloader...\n"
     ]
    }
   ],
   "source": [
    "# dataloader\n",
    "print(f'{datetime.datetime.now()} - Preparing train_dataloader...')\n",
    "train_data = triplet_CQT(out_length=400, is_label=kwargs['is_label'], is_random=kwargs['is_random'])\n",
    "train_dataloader = DataLoader(train_data, opt.batch_size, shuffle=True, num_workers=opt.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "imposed-holly",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Â§ö‰∏™epochÁöÑËÆ≠ÁªÉ+ÊµãËØï\n",
    "def train(max_epoch):\n",
    "    model.train()\n",
    "    model.module.model.train()\n",
    "    best_MAP = 0\n",
    "    for epoch in range(max_epoch):\n",
    "        print(f'---------epoch {epoch}----------')\n",
    "        running_loss = 0\n",
    "        num = 0\n",
    "        for ii, (a, p, n, la, lp, ln) in tqdm(enumerate(train_dataloader)):\n",
    "            B, _, _, _ = a.shape\n",
    "            target = torch.cat((torch.ones(B), torch.zeros(B))).cuda()\n",
    "            # train model\n",
    "            # a = a.requires_grad_().to(opt.device)\n",
    "            # p = p.requires_grad_().to(opt.device)\n",
    "            # n = n.requires_grad_().to(opt.device)\n",
    "            a, p, n = a.cuda(device=device_ids[0]), p.cuda(device=device_ids[0]), n.cuda(device=device_ids[0])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(a, p, n)\n",
    "            pred = pred.squeeze(1)\n",
    "            loss = loss_fn(pred, target)\n",
    "            print(loss)\n",
    "            loss = loss.sum()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            num += B\n",
    "\n",
    "            if (ii+1) % 4 == 0 :\n",
    "                print(num)\n",
    "                running_loss /= num\n",
    "                print(\"train_loss:\", running_loss)\n",
    "\n",
    "#                     MAP = 0\n",
    "#                     print(\"Youtube350:\")\n",
    "#                     MAP += val_slow_batch(model, val_dataloader, batch=100, is_dis=kwargs['zo'])\n",
    "#                     print(\"CoverSong80:\")\n",
    "#                     MAP += val_slow_batch(model, val_dataloader80, batch=100, is_dis=kwargs['zo'])\n",
    "                # print(\"Youtube350:\")\n",
    "                # MAP += val_quick(model, val_dataloader)\n",
    "                # print(\"CoverSong80:\")\n",
    "                # MAP += val_quick(model, val_dataloader80)\n",
    "                # print(\"Marukars:\")\n",
    "                # MAP += val_slow_batch(model, val_dataloader_marukars, batch=100, is_dis=kwargs['zo'])\n",
    "#                     if MAP > best_MAP:\n",
    "#                         best_MAP = MAP\n",
    "#                         print('*****************BEST*****************')\n",
    "#                     if kwargs['save_model'] == True:\n",
    "#                         if parallel:\n",
    "#                             model.module.save(opt.notes)\n",
    "#                         else:\n",
    "#                             model.save(opt.notes)\n",
    "                scheduler.step(running_loss)\n",
    "                running_loss = 0\n",
    "                num = 0\n",
    "\n",
    "            \n",
    "#         if loss.item() != loss.item():\n",
    "#             print('Train NaN!')\n",
    "#             print(loss_gpus)\n",
    "#             print('====================================================')\n",
    "#             torch.save((X,y), os.path.join(save_dir, 'Xy_nan.pt'))\n",
    "#             torch.save(model.state_dict(), os.path.join(save_dir, 'model_nan.pth'))\n",
    "#             exit()\n",
    "\n",
    "            \n",
    "#     scheduler.step()\n",
    "#     return loss_total/batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "correct-currency",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn, out_floor):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        size = len(dataloader.dataset)\n",
    "        batch_num = math.ceil(size/dataloader.batch_size)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_loss_v, test_loss_nv = 0, 0\n",
    "        test_loss_f, test_loss_t = 0, 0\n",
    "        oa_avg, vr_avg, vfa_avg, rpa_avg, rca_avg = 0, 0, 0, 0, 0\n",
    "    \n",
    "    \n",
    "        for X, y in dataloader:\n",
    "            # X, y = X.to(device), y.to(device)\n",
    "            X, y = X.cuda(device=device_ids[0]), y.cuda(device=device_ids[0])\n",
    "            Xpred = model(X, out_floor)\n",
    "            Xout = utils.salience_to_output(Xpred.clone().detach(), threshold=threshold)\n",
    "            \n",
    "            if out_floor == 0:\n",
    "                loss = loss_fn(Xpred, y, threshold)\n",
    "                oa, vr, vfa, rpa, rca = evaluate.evaluate(Xout, y, out_floor)\n",
    "            else:\n",
    "                y_downsample = utils.downsample(y, out_floor)\n",
    "                loss = loss_fn(Xpred, y_downsample, threshold)\n",
    "                oa, vr, vfa, rpa, rca = evaluate.evaluate(Xout, y_downsample, out_floor)\n",
    "                \n",
    "            if args.loss == 2:\n",
    "                loss_gather = (loss[0].sum()+loss[2].sum())/(loss[1].sum()+loss[3].sum())\n",
    "                loss_v_gather = loss[0].sum()/loss[1].sum() if loss[1].sum() else loss[1].sum()*0\n",
    "                loss_nv_gather = loss[2].sum()/loss[3].sum() if loss[3].sum() else loss[3].sum()*0\n",
    "                test_loss_v += loss_v_gather.item()\n",
    "                test_loss_nv += loss_nv_gather.item()\n",
    "            elif args.loss in [3,4]:\n",
    "                loss_gather = (loss[0].sum()+loss[2].sum())/(loss[1].sum()+loss[3].sum())\n",
    "                loss_f_gather = loss[0].sum()/loss[1].sum() if loss[1].sum() else loss[1].sum()*0\n",
    "                loss_t_gather = loss[2].sum()/loss[3].sum() if loss[3].sum() else loss[3].sum()*0\n",
    "                test_loss_f += loss_f_gather.item()\n",
    "                test_loss_t += loss_t_gather.item()\n",
    "            elif args.loss in [0,1]:\n",
    "                loss_gather = loss.sum()\n",
    "                \n",
    "            if loss_gather.item() != loss_gather.item():\n",
    "                print('Test NaN!')\n",
    "                print(loss)\n",
    "                print('====================================================')\n",
    "                torch.save((X,y), os.path.join(save_dir, 'Xy_nan.pt'))\n",
    "                torch.save(model.state_dict(), os.path.join(save_dir, 'model_nan.pth'))\n",
    "                exit()\n",
    "            \n",
    "            test_loss += loss_gather.item()\n",
    "            \n",
    "    \n",
    "    print(f\"Test Error: Avg loss: {test_loss:.4f} \\n\")\n",
    "    print(f\"Test OA\\t{oa_avg:.4f}\\tVR\\t{vr_avg:.4f}\\tVFA\\t{vfa_avg:.4f}\\tRPA\\t{rpa_avg:.4f}\\tRCA\\t{rca_avg:.4f}\\n\")\n",
    "    \n",
    "    if args.loss in [0,1,2]:\n",
    "        return (test_loss, test_loss_v, test_loss_nv), oa_avg, vr_avg, vfa_avg, rpa_avg, rca_avg\n",
    "    elif args.loss in [3,4]:\n",
    "        return (test_loss, test_loss_f, test_loss_t), oa_avg, vr_avg, vfa_avg, rpa_avg, rca_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "light-neighbor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------epoch 0----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/yangds/anaconda3/envs/csi2/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/yangds/anaconda3/envs/csi2/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11.8115,  6.9740,  0.5494], device='cuda:0', grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:10, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0079, 6.3098, 4.7275], device='cuda:0', grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:12,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8137, 1.7301, 8.7336], device='cuda:0', grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:14,  4.71s/it]\n"
     ]
    }
   ],
   "source": [
    "train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a,p,n,la,lp,ln in train_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, p, n = a.cuda(device=device_ids[0]), p.cuda(device=device_ids[0]), n.cuda(device=device_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.module.model.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(a,p,n).squeeze(0)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-jewelry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-appliance",
   "metadata": {
    "code_folding": [
     18,
     22,
     30,
     43,
     50,
     61
    ]
   },
   "outputs": [],
   "source": [
    "# # ËÆ≠ÁªÉÊ®°Âûãüåü\n",
    "# Â§ö‰∏™epochËÆ≠ÁªÉÔºåÊØè‰∏™epochÂêéÂú®È™åËØÅÈõÜ‰∏äÊµãËØï\n",
    "\n",
    "best_oa = 0\n",
    "\n",
    "_, oa, _, _, _, _ = test(valid_dataloader, model, loss_fn, num_floor)\n",
    "print(f'È™åËØÅÈõÜÂéüÂßãOA: {oa:.4f}.')\n",
    "best_oa = oa\n",
    "\n",
    "for t in range(epochs_finished, epochs_finished+epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------{datetime.datetime.now()}\")\n",
    "    train_loss = train(train_dataloader, model, loss_fn, optimizer, scheduler_decay, num_floor)\n",
    "    valid_loss, oa, _, _, _, _ = test(valid_dataloader, model, loss_fn, num_floor)\n",
    "    test_loss, test_oa, _, _, _, _ = test(test_dataloader, model, loss_fn, num_floor)\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_oa_list.append(oa)\n",
    "    test_oa_list.append(test_oa)\n",
    "    if args.loss in [0,1]:\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        test_loss_list.append(test_loss)\n",
    "        scheduler_stop.step(valid_loss)\n",
    "    elif args.loss == 2:\n",
    "        valid_loss_list.append(valid_loss[0])\n",
    "        valid_loss_v_list.append(valid_loss[1])\n",
    "        valid_loss_nv_list.append(valid_loss[2])\n",
    "        scheduler_stop.step(valid_loss[0])\n",
    "        test_loss_list.append(test_loss[0])\n",
    "        test_loss_v_list.append(test_loss[1])\n",
    "        test_loss_nv_list.append(test_loss[2])\n",
    "    elif args.loss in [3,4]:\n",
    "        valid_loss_list.append(valid_loss[0])\n",
    "        valid_loss_f_list.append(valid_loss[1])\n",
    "        valid_loss_t_list.append(valid_loss[2])\n",
    "        scheduler_stop.step(valid_loss[0])\n",
    "        test_loss_list.append(test_loss[0])\n",
    "        test_loss_f_list.append(test_loss[1])\n",
    "        test_loss_t_list.append(test_loss[2])\n",
    "    \n",
    "    if optimizer.state_dict()['param_groups'][0]['lr']<=0:\n",
    "        print(f'Early stop after {t+1} epochs.')\n",
    "        break\n",
    "    \n",
    "    if args.loss in [0,1]:\n",
    "        plt.plot(range(1,len(train_loss_list)+1), train_loss_list, 'y')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_list, 'm')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_list, 'r')\n",
    "        plt.plot(range(1, len(valid_oa_list)+1), valid_oa_list, 'b')\n",
    "        plt.plot(range(1, len(test_oa_list)+1), test_oa_list, 'b--')\n",
    "        plt.legend(['train loss', 'valid loss', 'test_loss','valid acc','test acc'])\n",
    "    elif args.loss == 2:\n",
    "        plt.plot(range(1,len(train_loss_list)+1), train_loss_list, 'y')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_list, 'm')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_v_list, 'm--')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_nv_list, 'm-.')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_list, 'r')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_v_list, 'r--')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_nv_list, 'r-.')\n",
    "        plt.plot(range(1, len(valid_oa_list)+1), valid_oa_list, 'b')\n",
    "        plt.plot(range(1, len(test_oa_list)+1), test_oa_list, 'b--')\n",
    "        plt.legend(['train loss', 'valid loss', 'valid loss(V)', 'valid loss(NV)', 'test loss', 'test loss(V)', 'test loss(NV)','valid acc','test acc'])\n",
    "    elif args.loss in [3,4]:\n",
    "        plt.plot(range(1,len(train_loss_list)+1), train_loss_list, 'y')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_list, 'm')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_f_list, 'm--')\n",
    "        plt.plot(range(1,len(valid_loss_list)+1), valid_loss_t_list, 'm-.')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_list, 'r')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_f_list, 'r--')\n",
    "        plt.plot(range(1,len(test_loss_list)+1), test_loss_t_list, 'r-.')\n",
    "        plt.plot(range(1, len(valid_oa_list)+1), valid_oa_list, 'b')\n",
    "        plt.plot(range(1, len(test_oa_list)+1), test_oa_list, 'b--')\n",
    "        plt.legend(['train loss', 'valid loss', 'valid loss(F)', 'valid loss(T)', 'test loss', 'test loss(F)', 'test loss(T)','valid acc','test acc'])\n",
    "    \n",
    "    plt.savefig(os.path.join(save_dir, 'loss.png'))\n",
    "    \n",
    "    # ‰øùÂ≠òÊúÄ‰ºòÊ®°Âûã\n",
    "    if oa > best_oa:\n",
    "        with torch.no_grad():\n",
    "            print(f'[in epoch {t+1}, OA got new best: from {best_oa:.4f} to {oa:.4f}. Will save the model]')\n",
    "            best_oa = oa\n",
    "            # torch.save(model, os.path.join(save_dir, f'model_floor{num_floor}_best.pth'))\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, f'model_floor{num_floor}_best.pth'))\n",
    "    \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:csi2]",
   "language": "python",
   "name": "conda-env-csi2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
