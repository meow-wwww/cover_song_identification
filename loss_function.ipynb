{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "原始函数，CrossEntropyLoss_Origin的内核\n",
    "def cross_entropy_multilayer_simplify(sm, one_hot): \n",
    "    # sm one_hot都是多片的\n",
    "    # 论文原始版本\n",
    "        # 可以优化的方向：对unvoicing的部分加以控制：平方误差or dual loss?\n",
    "    assert(sm.shape == one_hot.shape)\n",
    "    batch_size, case, _ = sm.shape\n",
    "    print(batch_size, case)\n",
    "    none_zero_lines = one_hot.bool().any(len(one_hot.shape)-1)\n",
    "    # print(none_zero_lines)\n",
    "    return (-torch.log(sm)*one_hot).sum()/none_zero_lines.sum()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss_Origin(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLoss_Origin, self).__init__()\n",
    "        return\n",
    "    def forward(self, output, one_hot):\n",
    "        '''\n",
    "        output: network output(not softmax yet)\n",
    "                shape: [N, 1, f, t]\n",
    "        one_hot: ground truth(has not been gaussian blurred)\n",
    "                shape: [N, f, t]\n",
    "        [OUTPUT]是一个batch中不同样本的均值\n",
    "        '''\n",
    "        output = output.squeeze(dim=1) # output: [N, f, t]\n",
    "        \n",
    "        output_minus = output - output.max() # 防止softmax溢出\n",
    "        sm = func.softmax(output_minus, dim=-2)\n",
    "\n",
    "        none_zero_lines_num = one_hot.bool().any(1).sum()\n",
    "        \n",
    "        if none_zero_lines_num == 0: # 在这里曾经因为除以0发生了一次NaN (╥﹏╥)\n",
    "            return (-torch.log(sm)*one_hot).sum()*0 # 其实直接return一个0tensor也行，但考虑到device，还是这样写吧\n",
    "        else:\n",
    "            return (-torch.log(sm)*one_hot).sum()/none_zero_lines_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss_for_FA_CE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLoss_for_FA_CE, self).__init__()\n",
    "        return\n",
    "    def forward(self, output, one_hot):\n",
    "        '''\n",
    "        output: network output(not softmax yet)\n",
    "                shape: [N, 1, f, t]\n",
    "        one_hot: ground truth(has not been gaussian blurred)\n",
    "                shape: [N, f, t]\n",
    "        [OUTPUT]是一个batch中不同样本的均值\n",
    "        '''\n",
    "        output = output.squeeze(dim=1) # output: [N, f, t]\n",
    "        output_minus = output - output.max() # 防止softmax溢出\n",
    "        sm = func.softmax(output_minus, dim=-2)\n",
    "        \n",
    "        # 对one-hot进行处理，没有label的全零列改成1/360\n",
    "\n",
    "        none_zero_lines = one_hot.bool().any(1).reshape(-1)\n",
    "        one_hot = one_hot.float()\n",
    "        index0 = torch.tensor([list(range(one_hot.shape[0]))]*one_hot.shape[2]).T.reshape(-1)[none_zero_lines == False]\n",
    "        index2 = torch.tensor([list(range(one_hot.shape[2]))]*one_hot.shape[0]).reshape(-1)[none_zero_lines == False]\n",
    "        one_hot[index0, :, index2] = 1/one_hot.shape[1]\n",
    "        \n",
    "        return (-torch.log(sm)*one_hot).sum()/(output.shape[2]*output.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "surgical-joyce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6f9c7c345017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mCrossEntropyLoss_for_FA_CE_VNV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCrossEntropyLoss_for_FA_CE_VNV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class CrossEntropyLoss_for_FA_CE_VNV(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLoss_for_FA_CE_VNV, self).__init__()\n",
    "        return\n",
    "    def forward(self, output, one_hot):\n",
    "        '''\n",
    "        output: network output(not softmax yet)\n",
    "                shape: [N, 1, f, t]\n",
    "        one_hot: ground truth(has not been gaussian blurred)\n",
    "                shape: [N, f, t]\n",
    "        [OUTPUT]是一个batch中不同样本的均值\n",
    "        '''\n",
    "        output = output.squeeze(dim=1) # output: [N, f, t]\n",
    "        output_minus = output - output.max() # 防止softmax溢出\n",
    "        sm = func.softmax(output_minus, dim=-2)\n",
    "        \n",
    "        # 对one-hot进行处理，没有label的全零列改成1/f\n",
    "\n",
    "        none_zero_lines = one_hot.bool().any(1).reshape(-1)\n",
    "        one_hot_float = one_hot.float()\n",
    "        index0 = torch.tensor([list(range(one_hot_float.shape[0]))]*one_hot_float.shape[2]).T.reshape(-1)[none_zero_lines == False]\n",
    "        index2 = torch.tensor([list(range(one_hot_float.shape[2]))]*one_hot_float.shape[0]).reshape(-1)[none_zero_lines == False]\n",
    "        one_hot_float[index0, :, index2] = 1/one_hot_float.shape[1]\n",
    "        \n",
    "        loss_all = (-torch.log(sm)*one_hot_float).sum() # scalar tensor\n",
    "        num_all = output.shape[2]*output.shape[0]\n",
    "        # ----------------------------------------------------------------------\n",
    "        none_zero_lines_num = none_zero_lines.sum()\n",
    "        if none_zero_lines_num == 0:\n",
    "            loss_voicing = loss_all*0\n",
    "            num_voicing = 0\n",
    "        else:\n",
    "            loss_voicing = (-torch.log(sm)*one_hot).sum()\n",
    "            num_voicing = none_zero_lines_num\n",
    "            \n",
    "        loss_unvoicing = loss_all - loss_voicing\n",
    "        num_unvoicing = num_all - num_unvoicing\n",
    "        \n",
    "        return loss_voicing, num_voicing, loss_unvoicing, num_unvoicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-balloon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
