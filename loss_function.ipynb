{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "attractive-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "原始函数，CrossEntropyLoss_Origin的内核\n",
    "def cross_entropy_multilayer_simplify(sm, one_hot): \n",
    "    # sm one_hot都是多片的\n",
    "    # 论文原始版本\n",
    "        # 可以优化的方向：对unv oicing的部分加以控制：平方误差or dual loss?\n",
    "    assert(sm.shape == one_hot.shape)\n",
    "    batch_size, case, _ = sm.shape\n",
    "    print(batch_size, case)\n",
    "    none_zero_lines = one_hot.bool().any(len(one_hot.shape)-1)\n",
    "    # print(none_zero_lines)\n",
    "    return (-torch.log(sm)*one_hot).sum()/none_zero_lines.sum()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss_Origin(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLoss_Origin, self).__init__()\n",
    "        return\n",
    "    def forward(self, output, one_hot):\n",
    "        '''\n",
    "        output: network output(not softmax yet)\n",
    "                shape: [N, 1, f, t]\n",
    "        one_hot: ground truth(has not been gaussian blurred)\n",
    "                shape: [N, f, t]\n",
    "        [OUTPUT]是一个batch中不同样本的均值\n",
    "        '''\n",
    "        output = output.squeeze(dim=1) # output: [N, f, t]\n",
    "        \n",
    "        sm = output + 1e-20\n",
    "\n",
    "        none_zero_lines_num = one_hot.bool().any(1).sum()\n",
    "        \n",
    "        if none_zero_lines_num == 0: # 在这里曾经因为除以0发生了一次NaN (╥﹏╥)\n",
    "            return (-torch.log(sm)*one_hot).sum()*0 # 其实直接return一个0tensor也行，但考虑到device，还是这样写吧\n",
    "        else:\n",
    "            return (-torch.log(sm)*one_hot).sum()/none_zero_lines_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss_for_FA_CE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLoss_for_FA_CE, self).__init__()\n",
    "        return\n",
    "    def forward(self, output, one_hot):\n",
    "        '''\n",
    "        output: network output(not softmax yet)\n",
    "                shape: [N, 1, f, t]\n",
    "        one_hot: ground truth(has not been gaussian blurred)\n",
    "                shape: [N, f, t]\n",
    "        [OUTPUT]是一个batch中不同样本的均值\n",
    "        '''\n",
    "        output = output.squeeze(dim=1) # output: [N, f, t]\n",
    "        sm = output + 1e-20\n",
    "        \n",
    "        # 对one-hot进行处理，没有label的全零列改成1/360\n",
    "\n",
    "        none_zero_lines = one_hot.bool().any(1).reshape(-1)\n",
    "        one_hot = one_hot.float()\n",
    "        index0 = torch.tensor([list(range(one_hot.shape[0]))]*one_hot.shape[2]).T.reshape(-1)[none_zero_lines == False]\n",
    "        index2 = torch.tensor([list(range(one_hot.shape[2]))]*one_hot.shape[0]).reshape(-1)[none_zero_lines == False]\n",
    "        one_hot[index0, :, index2] = 1/one_hot.shape[1]\n",
    "        \n",
    "        return (-torch.log(sm)*one_hot).sum()/(output.shape[2]*output.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss_for_FA_SQ(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLoss_for_FA_CE, self).__init__()\n",
    "        return\n",
    "    def forward(self, output, one_hot):\n",
    "        '''\n",
    "        output: network output(not softmax yet)\n",
    "                shape: [N, 1, f, t]\n",
    "        one_hot: ground truth(has not been gaussian blurred)\n",
    "                shape: [N, f, t]\n",
    "        [OUTPUT]是一个batch中不同样本的均值\n",
    "        '''\n",
    "        output = output.squeeze(dim=1) # output: [N, f, t]\n",
    "        sm = output + 1e-20\n",
    "        \n",
    "        none_zero_lines_num = one_hot.bool().any(1).sum()\n",
    "        \n",
    "        if none_zero_lines_num == 0:\n",
    "            return (-torch.log(sm)*one_hot).sum()*0\n",
    "        else:\n",
    "            return (-torch.log(sm)*one_hot).sum()/none_zero_lines_num\n",
    "        \n",
    "        # 对one-hot进行处理，没有label的全零列改成1/360\n",
    "\n",
    "        none_zero_lines = one_hot.bool().any(1).reshape(-1)\n",
    "        one_hot = one_hot.float()\n",
    "        index0 = torch.tensor([list(range(one_hot.shape[0]))]*one_hot.shape[2]).T.reshape(-1)[none_zero_lines == False]\n",
    "        index2 = torch.tensor([list(range(one_hot.shape[2]))]*one_hot.shape[0]).reshape(-1)[none_zero_lines == False]\n",
    "        one_hot[index0, :, index2] = 1/one_hot.shape[1]\n",
    "        \n",
    "        return (-torch.log(sm)*one_hot).sum()/(output.shape[2]*output.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "surgical-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss_for_FA_CE_VNV(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLoss_for_FA_CE_VNV, self).__init__()\n",
    "    def forward(self, output, one_hot):\n",
    "        '''\n",
    "        output: network output(not softmax yet)\n",
    "                shape: [N, 1, f, t]\n",
    "        one_hot: ground truth(has not been gaussian blurred)\n",
    "                shape: [N, f, t]\n",
    "        [OUTPUT]是一个batch中不同样本的均值\n",
    "        '''\n",
    "        output = output.squeeze(dim=1) # output: [N, f, t]\n",
    "        sm = output + 1e-20\n",
    "        \n",
    "        # 对one-hot进行处理，没有label的全零列改成1/f\n",
    "\n",
    "        none_zero_lines = one_hot.bool().any(1).reshape(-1)\n",
    "        one_hot_float = one_hot.float()\n",
    "        index0 = torch.tensor([list(range(one_hot_float.shape[0]))]*one_hot_float.shape[2]).T.reshape(-1)[none_zero_lines == False]\n",
    "        index2 = torch.tensor([list(range(one_hot_float.shape[2]))]*one_hot_float.shape[0]).reshape(-1)[none_zero_lines == False]\n",
    "        one_hot_float[index0, :, index2] = 1/one_hot_float.shape[1]\n",
    "        \n",
    "        loss_all = (-torch.log(sm)*one_hot_float).sum() # scalar tensor\n",
    "        num_all = output.shape[2]*output.shape[0]\n",
    "        \n",
    "        none_zero_lines_num = none_zero_lines.sum()\n",
    "        if none_zero_lines_num == 0: # 全是unvoicing\n",
    "            loss_voicing = loss_all*0\n",
    "            num_voicing = loss_all*0\n",
    "        else:\n",
    "            loss_voicing = (-torch.log(sm)*one_hot).sum()\n",
    "            num_voicing = none_zero_lines_num\n",
    "            \n",
    "        loss_unvoicing = loss_all - loss_voicing\n",
    "        num_unvoicing = loss_all*0 + (num_all - num_voicing)\n",
    "        return loss_voicing, num_voicing, loss_unvoicing, num_unvoicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-samba",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "class CrossEntropyLoss_for_FA_CE_TF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CrossEntropyLoss_for_FA_CE_TF, self).__init__()\n",
    "    def forward(self, output, one_hot):\n",
    "        '''\n",
    "        output: network output(not softmax yet)\n",
    "                shape: [N, 1, f, t]\n",
    "        one_hot: ground truth(has not been gaussian blurred)\n",
    "                shape: [N, f, t]\n",
    "        [OUTPUT]是一个batch中不同样本的均值\n",
    "        '''\n",
    "        output = output.squeeze(dim=1) # output: [N, f, t]\n",
    "        sm = output + 1e-20\n",
    "        \n",
    "        # 预测结果 T or F\n",
    "        Xout = utils.salience_to_output(output.clone().detach(), threshold=0.05).to(torch.int32)\n",
    "        cmp_time = (Xout != one_hot).to(torch.int32).sum(dim=1).bool().to(torch.int32)\n",
    "        \n",
    "        # 对one-hot进行处理，没有label的全零列改成1/f\n",
    "\n",
    "        none_zero_lines = one_hot.bool().any(1).reshape(-1)\n",
    "        one_hot_float = one_hot.float()\n",
    "        index0 = torch.tensor([list(range(one_hot_float.shape[0]))]*one_hot_float.shape[2]).T.reshape(-1)[none_zero_lines == False]\n",
    "        index2 = torch.tensor([list(range(one_hot_float.shape[2]))]*one_hot_float.shape[0]).reshape(-1)[none_zero_lines == False]\n",
    "        one_hot_float[index0, :, index2] = 1/one_hot_float.shape[1]\n",
    "        \n",
    "        loss_all = (-torch.log(sm)*one_hot_float).sum() # scalar tensor\n",
    "        num_all = output.shape[2]*output.shape[0]\n",
    "        # ----------------------------------------------------------------------\n",
    "        loss_time = (-torch.log(sm)*one_hot_float).sum(dim=1) # scalar tensor\n",
    "        \n",
    "        False_loss = (loss_time * cmp_time).sum()\n",
    "        True_loss = loss_time.sum() - False_loss\n",
    "        False_num = cmp_time.sum()\n",
    "        True_num = num_all - False_num\n",
    "        \n",
    "        # ----------------------------------------------------------------------\n",
    "        '''none_zero_lines_num = none_zero_lines.sum()\n",
    "        if none_zero_lines_num == 0: # 全是unvoicing\n",
    "            loss_voicing = loss_all*0\n",
    "            num_voicing = loss_all*0\n",
    "        else:\n",
    "            loss_voicing = (-torch.log(sm)*one_hot).sum()\n",
    "            num_voicing = none_zero_lines_num\n",
    "            \n",
    "        loss_unvoicing = loss_all - loss_voicing\n",
    "        num_unvoicing = loss_all*0 + (num_all - num_voicing)'''\n",
    "        \n",
    "        return False_loss, False_num, True_loss, True_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hahaha"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
